"""
ì •ì±… ì‹œì°¨ë¥¼ ê³ ë ¤í•œ ì²­ë…„ ì´ë™ ë¶„ì„ ëª¨ë“ˆ
=====================================

ì´ ëª¨ë“ˆì€ ì •ì±… ì‹œí–‰ê³¼ ì²­ë…„ ì¸êµ¬ ì´ë™ ê°„ì˜ ì‹œê°„ì°¨ë¥¼ ê³ ë ¤í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
- ë¶„ì„ ê¸°ê°„: 2023ë…„ 8ì›” ~ 2024ë…„ 7ì›” (12ê°œì›”)
- ì •ì±… ì‹œì°¨: ì •ì±… ì‹œí–‰ í›„ ì‹¤ì œ íš¨ê³¼ê°€ ë‚˜íƒ€ë‚˜ê¸°ê¹Œì§€ì˜ ì§€ì—° ì‹œê°„ì„ ê³ ë ¤
- ì²­ë…„ ì´ë™ íŒ¨í„´ê³¼ ì •ì±… íš¨ê³¼ì„±ì˜ ì‹œê³„ì—´ ìƒê´€ê´€ê³„ ë¶„ì„
"""

import warnings
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats

warnings.filterwarnings("ignore")

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams["font.family"] = ["AppleGothic", "Malgun Gothic", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False


class PolicyLagAnalyzer:
    """ì •ì±… ì‹œì°¨ë¥¼ ê³ ë ¤í•œ ì²­ë…„ ì´ë™ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, base_path=None):
        if base_path is None:
            self.base_path = Path(__file__).parent.parent
        else:
            self.base_path = Path(base_path)

        self.policy_data = None
        self.migration_data = None
        self.analysis_period_data = None
        self.merged_data = None

        # ë¶„ì„ ê¸°ê°„ ì„¤ì • (2023ë…„ 8ì›” ~ 2024ë…„ 7ì›”)
        self.start_year_month = 202308
        self.end_year_month = 202407

        print(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {self.start_year_month} ~ {self.end_year_month}")

    def load_data(self):
        """ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        # ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ
        metropolitan_policy_file = (
            self.base_path / "data/policy_eval/ê´‘ì—­_ì²­ë…„ì •ì±…_ì¢…í•©í‰ê°€ê²°ê³¼.csv"
        )

        # ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ
        municipal_policy_file = (
            self.base_path / "data/policy_eval/ê¸°ì´ˆ_ì²­ë…„ì •ì±…_ì¢…í•©í‰ê°€ê²°ê³¼.csv"
        )

        policy_data_list = []

        if metropolitan_policy_file.exists():
            metro_data = pd.read_csv(metropolitan_policy_file, encoding="utf-8-sig")
            print(f"âœ… ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ: {len(metro_data)}ê°œ ì§€ì—­")
            policy_data_list.append(metro_data)
        else:
            print("âŒ ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if municipal_policy_file.exists():
            muni_data = pd.read_csv(municipal_policy_file, encoding="utf-8-sig")
            print(f"âœ… ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ: {len(muni_data)}ê°œ ì§€ì—­")
            policy_data_list.append(muni_data)
        else:
            print("âŒ ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if not policy_data_list:
            print("âŒ ì •ì±… ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë‘ ë°ì´í„°ë¥¼ í•©ì¹˜ê¸°
        self.policy_data = pd.concat(policy_data_list, ignore_index=True)
        print(f"âœ… ì „ì²´ ì •ì±… ë°ì´í„° í†µí•©: {len(self.policy_data)}ê°œ ì§€ì—­")

        # ê´‘ì—­/ê¸°ì´ˆ êµ¬ë¶„ì„ ìœ„í•œ ë°ì´í„° ì €ì¥
        self.metropolitan_data = (
            metro_data if metropolitan_policy_file.exists() else None
        )
        self.municipal_data = muni_data if municipal_policy_file.exists() else None

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ
        migration_dir = self.base_path / "data/migration/ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰_consolidated"

        if not migration_dir.exists():
            print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ë“¤ ì°¾ê¸°
        target_files = []
        current_ym = self.start_year_month

        while current_ym <= self.end_year_month:
            file_path = migration_dir / f"youth_total_migration_{current_ym}.csv"
            if file_path.exists():
                target_files.append(file_path)
                print(f"   ğŸ“… {current_ym} ë°ì´í„° ë°œê²¬")

            # ë‹¤ìŒ ì›”ë¡œ ì¦ê°€
            current_month = current_ym % 100
            current_year = current_ym // 100

            if current_month == 12:
                current_ym = (current_year + 1) * 100 + 1
            else:
                current_ym = current_year * 100 + (current_month + 1)

        if not target_files:
            print("âŒ ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë°ì´í„° í†µí•©
        dfs = []
        for file in sorted(target_files):
            try:
                year_month = file.stem.split("_")[-1]
                df = pd.read_csv(file, encoding="utf-8-sig")
                df["ì—°ì›”"] = year_month
                df["ì—°ë„"] = int(year_month[:4])
                df["ì›”"] = int(year_month[4:])
                dfs.append(df)
                print(f"   âœ… {year_month} ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {file}: {e}")
                continue

        if dfs:
            self.migration_data = pd.concat(dfs, ignore_index=True)
            print(
                f"âœ… ì´ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ: {len(self.migration_data)}ê°œ ë ˆì½”ë“œ"
            )
            return True
        else:
            print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False

    def preprocess_migration_data(self):
        """íŒŒì¼ë³„ë¡œ ê° ì§€ì—­ì˜ ì»¬ëŸ¼í•©(ì „ì…), rowí•©(ì „ì¶œ) ëˆ„ì  ë°©ì‹ìœ¼ë¡œ ìˆœì´ë™ ê³„ì‚°"""
        migration_dir = self.base_path / "data/migration/ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰_consolidated"
        if not migration_dir.exists():
            print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë¶„ì„ ê¸°ê°„ íŒŒì¼ ëª©ë¡
        target_files = []
        current_ym = self.start_year_month
        while current_ym <= self.end_year_month:
            file_path = migration_dir / f"youth_total_migration_{current_ym}.csv"
            if file_path.exists():
                target_files.append(file_path)
            current_month = current_ym % 100
            current_year = current_ym // 100
            if current_month == 12:
                current_ym = (current_year + 1) * 100 + 1
            else:
                current_ym = current_year * 100 + (current_month + 1)
        if not target_files:
            print("âŒ ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ëª¨ë“  ì§€ì—­ëª… ì§‘í•©
        all_regions = set()
        for file in target_files:
            df = pd.read_csv(file, encoding="utf-8-sig")
            all_regions.update(df.columns[1:])  # ì²« ì»¬ëŸ¼ì€ ì§€ì—­ëª…(row)
            all_regions.update(df.iloc[:, 0].unique())
        all_regions = sorted(all_regions)

        # ëˆ„ì ìš© dict
        inflow_dict = {region: 0 for region in all_regions}
        outflow_dict = {region: 0 for region in all_regions}

        # íŒŒì¼ë³„ë¡œ ëˆ„ì 
        for file in target_files:
            df = pd.read_csv(file, encoding="utf-8-sig")
            df = df.fillna(0)
            # ì»¬ëŸ¼: [ì§€ì—­ëª…, ...]
            col_regions = df.columns[1:]
            row_regions = df.iloc[:, 0]
            # ì „ì…: ê° ì§€ì—­ë³„ ì»¬ëŸ¼ í•©
            for region in col_regions:
                inflow_dict[region] += df[region].sum()
            # ì „ì¶œ: ê° ì§€ì—­ë³„ row í•©
            for idx, region in enumerate(row_regions):
                outflow_dict[region] += df.iloc[idx, 1:].sum()

        # ê²°ê³¼ DataFrame
        result = []
        for region in all_regions:
            inflow = inflow_dict[region]
            outflow = outflow_dict[region]
            net = inflow - outflow
            result.append(
                {"ì§€ì—­ëª…": region, "ì „ì…": inflow, "ì „ì¶œ": outflow, "ìˆœì´ë™": net}
            )
        self.analysis_period_data = pd.DataFrame(result)
        print(
            f"âœ… íŒŒì¼ ëˆ„ì  ë°©ì‹ ìˆœì´ë™ ê³„ì‚° ì™„ë£Œ: {len(self.analysis_period_data)}ê°œ ì§€ì—­"
        )
        return True

    def _region_names_match(self, col_name, region_name):
        """ì»¬ëŸ¼ëª…ê³¼ ì§€ì—­ëª…ì´ ë§¤ì¹˜ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        if pd.isna(col_name) or pd.isna(region_name):
            return False

        col_str = str(col_name).strip()
        region_str = str(region_name).strip()

        # ì™„ì „ ì¼ì¹˜
        if col_str == region_str:
            return True

        # ê³µë°± ì œê±° í›„ ì¼ì¹˜
        if col_str.replace(" ", "") == region_str.replace(" ", ""):
            return True

        # ì¼ë¶€ í‚¤ì›Œë“œ í¬í•¨ í™•ì¸ (ì‹œë„ëª… ë“±)
        if len(region_str) > 2:
            region_parts = region_str.split()
            for part in region_parts:
                if len(part) > 1 and part in col_str:
                    return True

        return False

    def merge_policy_migration_data(self):
        """ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° í†µí•©"""
        if self.policy_data is None or self.analysis_period_data is None:
            print("âŒ ì •ì±… ë°ì´í„°, ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
            return False

        print("ğŸ”— ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë§¤ì¹­ ì¤‘...")

        # ì§€ì—­ëª… ì •ì œ ë° ë§¤ì¹­
        def normalize_region_name(name):
            """ì§€ì—­ëª… ì •ê·œí™”"""
            if pd.isna(name):
                return ""
            return str(name).strip().replace("  ", " ")

        # ì •ì±… ë°ì´í„° ì§€ì—­ëª… ì •ì œ
        self.policy_data["ì§€ì—­ëª…_ì •ì œ"] = self.policy_data["ì§€ì—­ëª…"].apply(
            normalize_region_name
        )

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì§€ì—­ëª… ì •ì œ
        self.analysis_period_data["ì§€ì—­ëª…_ì •ì œ"] = self.analysis_period_data[
            "ì§€ì—­ëª…"
        ].apply(normalize_region_name)

        # ë§¤ì¹­ ê°€ëŠ¥í•œ ì§€ì—­ í™•ì¸
        policy_regions = set(self.policy_data["ì§€ì—­ëª…_ì •ì œ"])
        migration_regions = set(self.analysis_period_data["ì§€ì—­ëª…_ì •ì œ"])

        print(f"ì •ì±… ë°ì´í„° ì§€ì—­ ìˆ˜: {len(policy_regions)}")
        print(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì§€ì—­ ìˆ˜: {len(migration_regions)}")

        matched_regions = policy_regions.intersection(migration_regions)
        print(f"2ê°œ ë°ì´í„° ëª¨ë‘ ë§¤ì¹­ ê°€ëŠ¥í•œ ì§€ì—­: {len(matched_regions)}ê°œ")

        # ì¼ë¶€ ì§€ì—­ëª… ì˜ˆì‹œ ì¶œë ¥
        print("\nì •ì±… ë°ì´í„° ì§€ì—­ëª… ì˜ˆì‹œ:")
        print(list(policy_regions)[:10])
        print("\në§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì§€ì—­ëª… ì˜ˆì‹œ:")
        print(list(migration_regions)[:10])

        # ì •ì±… + ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë³‘í•©
        self.merged_data = pd.merge(
            self.policy_data,
            self.analysis_period_data,
            left_on="ì§€ì—­ëª…_ì •ì œ",
            right_on="ì§€ì—­ëª…_ì •ì œ",
            how="inner",
            suffixes=("_ì •ì±…", "_ì´ë™"),
        )

        if len(self.merged_data) > 0:
            print(f"âœ… ì„±ê³µì ìœ¼ë¡œ í†µí•©ëœ ì§€ì—­: {len(self.merged_data)}ê°œ")

            # ë³‘í•© í›„ ì»¬ëŸ¼ ëª©ë¡ í™•ì¸ (ë””ë²„ê¹…ìš©)
            print(f"ë³‘í•© í›„ ì»¬ëŸ¼ ëª©ë¡: {list(self.merged_data.columns)}")
            print(f"ì²­ë…„ì¸êµ¬ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€: {'ì²­ë…„ì¸êµ¬' in self.merged_data.columns}")

            youth_pop_col = (
                "ì²­ë…„ì¸êµ¬" if "ì²­ë…„ì¸êµ¬" in self.merged_data.columns else None
            )
            if youth_pop_col is None:
                print("âŒ ì²­ë…„ì¸êµ¬ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False

            print(f"ì‚¬ìš©í•  ì²­ë…„ì¸êµ¬ ì»¬ëŸ¼: {youth_pop_col}")

            # ğŸ” ì²­ë…„ì¸êµ¬ ë°ì´í„° ë‹¨ìœ„ í™•ì¸
            print(f"\nğŸ” ì²­ë…„ì¸êµ¬ ë°ì´í„° í†µê³„:")
            print(f"  - ì»¬ëŸ¼ëª…: {youth_pop_col}")
            print(f"  - í‰ê· : {self.merged_data[youth_pop_col].mean():.1f}")
            print(f"  - ì¤‘ì•™ê°’: {self.merged_data[youth_pop_col].median():.1f}")
            print(f"  - ìµœì†Œê°’: {self.merged_data[youth_pop_col].min():.1f}")
            print(f"  - ìµœëŒ€ê°’: {self.merged_data[youth_pop_col].max():.1f}")

            # ğŸ” ìˆœì´ë™ ë°ì´í„° í™•ì¸
            print(f"\nğŸ” ìˆœì´ë™ ë°ì´í„° í†µê³„:")
            print(f"  - í‰ê· : {self.merged_data['ìˆœì´ë™'].mean():.1f}")
            print(f"  - ì¤‘ì•™ê°’: {self.merged_data['ìˆœì´ë™'].median():.1f}")
            print(f"  - ìµœì†Œê°’: {self.merged_data['ìˆœì´ë™'].min():.1f}")
            print(f"  - ìµœëŒ€ê°’: {self.merged_data['ìˆœì´ë™'].max():.1f}")

            # ìˆœì´ë™ë¥  ê³„ì‚° (ì²­ë…„ ì¸êµ¬ ìˆ˜ ëŒ€ë¹„ %)
            self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"] = (
                self.merged_data["ìˆœì´ë™"] / (self.merged_data[youth_pop_col] + 1)
            ) * 100  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜

            # ğŸ” ê³„ì‚°ëœ ìˆœì´ë™ë¥  í™•ì¸
            print(f"\nğŸ” ê³„ì‚°ëœ ìˆœì´ë™ë¥  í†µê³„:")
            print(f"  - í‰ê· : {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].mean():.3f}%")
            print(f"  - ì¤‘ì•™ê°’: {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].median():.3f}%")
            print(f"  - ìµœì†Œê°’: {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}%")
            print(f"  - ìµœëŒ€ê°’: {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%")

            # ğŸ” ì´ìƒì¹˜ ì§€ì—­ í™•ì¸ (ìˆœì´ë™ë¥  > 100%)
            outliers = self.merged_data[self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"] > 100]
            if len(outliers) > 0:
                print(f"\nâš ï¸ ìˆœì´ë™ë¥  100% ì´ˆê³¼ ì§€ì—­: {len(outliers)}ê°œ")
                print("ìƒìœ„ 5ê°œ ì§€ì—­:")
                top_outliers = outliers.nlargest(5, "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„")[
                    ["ì§€ì—­ëª…_ì •ì±…", "ìˆœì´ë™", youth_pop_col, "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]
                ]
                for _, row in top_outliers.iterrows():
                    print(
                        f"  - {row['ì§€ì—­ëª…_ì •ì±…']}: ìˆœì´ë™={row['ìˆœì´ë™']:,.0f}ëª…, ì²­ë…„ì¸êµ¬={row[youth_pop_col]:,.1f}ëª…, ìˆœì´ë™ë¥ ={row['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„']:.1f}%"
                    )

            # í†µí•© ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
            print("\ní†µí•©ëœ ì£¼ìš” ì§€ì—­:")
            sample_regions = self.merged_data["ì§€ì—­ëª…_ì •ì±…"].head(10).tolist()
            for region in sample_regions:
                print(f"  - {region}")

            print(f"\nğŸ“Š ìˆœì´ë™ë¥  í†µê³„:")
            print(
                f"  - í‰ê·  ìˆœì´ë™ë¥ : {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].mean():.3f}%"
            )
            print(
                f"  - ìˆœì´ë™ë¥  ë²”ìœ„: {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}% ~ {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%"
            )

            # ê²°ê³¼ CSVë¡œ ì €ì¥
            save_path = (
                self.base_path / "migration_plot/settlement_induction_result.csv"
            )
            self.merged_data.to_csv(save_path, index=False, encoding="utf-8-sig")
            print(f"âœ… í†µí•© ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: {save_path}")

            # ìƒìœ„/í•˜ìœ„ 5ê°œ ì§€ì—­ ì¶œë ¥
            top_regions = self.merged_data.nlargest(5, "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„")[
                ["ì§€ì—­ëª…_ì •ì±…", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ìˆœì´ë™", youth_pop_col]
            ]
            bottom_regions = self.merged_data.nsmallest(5, "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„")[
                ["ì§€ì—­ëª…_ì •ì±…", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ìˆœì´ë™", youth_pop_col]
            ]

            print(f"\nğŸ† ìˆœì´ë™ë¥  ìƒìœ„ 5ê°œ ì§€ì—­:")
            for _, row in top_regions.iterrows():
                print(
                    f"  - {row['ì§€ì—­ëª…_ì •ì±…']}: {row['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„']:.3f}% (ìˆœì´ë™: {row['ìˆœì´ë™']:,.0f}ëª…, ì²­ë…„ì¸êµ¬: {row[youth_pop_col]:,.0f}ëª…)"
                )

            print(f"\nğŸ”» ìˆœì´ë™ë¥  í•˜ìœ„ 5ê°œ ì§€ì—­:")
            for _, row in bottom_regions.iterrows():
                print(
                    f"  - {row['ì§€ì—­ëª…_ì •ì±…']}: {row['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„']:.3f}% (ìˆœì´ë™: {row['ìˆœì´ë™']:,.0f}ëª…, ì²­ë…„ì¸êµ¬: {row[youth_pop_col]:,.0f}ëª…)"
                )

            return True
        else:
            print("âŒ ë§¤ì¹­ë˜ëŠ” ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤. ì§€ì—­ëª… í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return False

    def analyze_policy_migration_correlation(self):
        """ì •ì±… íš¨ê³¼ì„±ê³¼ ì²­ë…„ ì´ë™ íŒ¨í„´ì˜ ìƒê´€ê´€ê³„ ë¶„ì„"""
        if self.merged_data is None or len(self.merged_data) == 0:
            print("âŒ í†µí•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        print("ğŸ“Š ì •ì±… ì‹œì°¨ ë°˜ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ ì¤‘...")

        # ë¶„ì„í•  ì§€í‘œ (ì •ê·œí™”ëœ ê°’ ì‚¬ìš©)
        policy_vars = [
            "ì¢…í•©ì ìˆ˜",
            "ì „ëµì _ê°•ë„_ì •ê·œí™”",
            "í–‰ì •ì _ê°•ë„_ì •ê·œí™”",
            "ì²­ë…„ì˜ˆì‚°_ë¹„ìœ¨",
            "ì²­ë…„ì¸êµ¬_ë¹„ìœ¨",
        ]
        migration_vars = ["ìˆœì´ë™", "ì „ì…", "ì „ì¶œ", "ì´ë™ë¥ ", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]

        # ìƒê´€ê´€ê³„ ê²°ê³¼ ì €ì¥
        correlation_results = []

        for policy_var in policy_vars:
            if policy_var not in self.merged_data.columns:
                continue

            for migration_var in migration_vars:
                if migration_var not in self.merged_data.columns:
                    continue

                # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
                valid_data = self.merged_data[[policy_var, migration_var]].dropna()

                if len(valid_data) < 10:  # ìµœì†Œ ë°ì´í„° ìˆ˜ í™•ì¸
                    continue

                # ìƒê´€ê´€ê³„ ê³„ì‚°
                corr_coef, p_value = stats.pearsonr(
                    valid_data[policy_var], valid_data[migration_var]
                )

                # ìœ ì˜ì„± í‘œì‹œ
                if p_value < 0.001:
                    significance = "***"
                elif p_value < 0.01:
                    significance = "**"
                elif p_value < 0.05:
                    significance = "*"
                else:
                    significance = ""

                correlation_results.append(
                    {
                        "ì •ì±…ì§€í‘œ": policy_var,
                        "ì´ë™ì§€í‘œ": migration_var,
                        "ìƒê´€ê³„ìˆ˜": corr_coef,
                        "pê°’": p_value,
                        "ìœ ì˜ì„±": significance,
                        "í‘œë³¸ìˆ˜": len(valid_data),
                    }
                )

        # ê²°ê³¼ ì¶œë ¥
        if correlation_results:
            corr_df = pd.DataFrame(correlation_results)

            print(
                f"\nğŸ“ˆ ì •ì±… ì‹œì°¨ ë°˜ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ (n={len(self.merged_data)}):"
            )
            print("=" * 90)

            for _, row in corr_df.iterrows():
                print(
                    f"{row['ì •ì±…ì§€í‘œ']:15} â†” {row['ì´ë™ì§€í‘œ']:15}: "
                    f"r = {row['ìƒê´€ê³„ìˆ˜']:6.3f}{row['ìœ ì˜ì„±']:3} "
                    f"(p = {row['pê°’']:6.3f}, n = {row['í‘œë³¸ìˆ˜']:3})"
                )

            # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ìƒì„±
            if len(corr_df) > 0:
                pivot_corr = corr_df.pivot(
                    index="ì •ì±…ì§€í‘œ", columns="ì´ë™ì§€í‘œ", values="ìƒê´€ê³„ìˆ˜"
                )

                plt.figure(figsize=(14, 8))
                sns.heatmap(
                    pivot_corr,
                    annot=True,
                    cmap="RdBu_r",
                    center=0,
                    square=True,
                    fmt=".3f",
                    cbar_kws={"shrink": 0.8},
                )
                plt.title(
                    "ì •ì±… íš¨ê³¼ì„± vs ì²­ë…„ ì´ë™ ìƒê´€ê´€ê³„\n(ì •ì±… ì‹œì°¨ ë°˜ì˜: 2023.08-2024.07, ìˆœì´ë™ë¥ ì€ ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)",
                    fontsize=14,
                    pad=20,
                )
                plt.tight_layout()
                plt.savefig(
                    self.base_path / "migration_plot/policy_lag_correlation.png",
                    dpi=300,
                    bbox_inches="tight",
                )
                plt.show()

            return corr_df
        else:
            print("âŒ ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    def create_settlement_induction_plot(self):
        """ì •ì±… ì¢…í•©ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯ ìƒì„± (ê´‘ì—­/ê¸°ì´ˆ/ì „ì²´)"""
        if self.merged_data is None:
            print("âŒ í†µí•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì¢…í•©ì ìˆ˜ë¥¼ ì •ì°© ìœ ë„ ë…¸ë ¥ ì§€ìˆ˜ë¡œ ì‚¬ìš©
        if (
            "ì¢…í•©ì ìˆ˜" in self.merged_data.columns
            and "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„" in self.merged_data.columns
        ):

            # ì§€ì—­ìœ í˜•ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
            metropolitan_data = (
                self.merged_data[self.merged_data["ì§€ì—­ìœ í˜•"] == "ê´‘ì—­ìì¹˜ë‹¨ì²´"].copy()
                if "ì§€ì—­ìœ í˜•" in self.merged_data.columns
                else pd.DataFrame()
            )

            municipal_data = (
                self.merged_data[self.merged_data["ì§€ì—­ìœ í˜•"] == "ê¸°ì´ˆìì¹˜ë‹¨ì²´"].copy()
                if "ì§€ì—­ìœ í˜•" in self.merged_data.columns
                else pd.DataFrame()
            )

            # 3x1 ì„œë¸Œí”Œë¡¯ ìƒì„±
            fig, axes = plt.subplots(1, 3, figsize=(30, 8))

            # 1. ê´‘ì—­ìì¹˜ë‹¨ì²´ í”Œë¡¯
            if len(metropolitan_data) > 0:
                valid_metro = metropolitan_data[
                    ["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ëª…_ì •ì±…"]
                ].dropna()

                if len(valid_metro) > 0:
                    x_metro = valid_metro["ì¢…í•©ì ìˆ˜"]
                    y_metro = valid_metro["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]

                    # ì‚°ì ë„
                    axes[0].scatter(
                        x_metro,
                        y_metro,
                        alpha=0.7,
                        s=120,
                        c="steelblue",
                        edgecolors="white",
                        linewidth=1,
                    )

                    # íšŒê·€ì„  ì¶”ê°€
                    if len(valid_metro) > 2:
                        z = np.polyfit(x_metro, y_metro, 1)
                        p = np.poly1d(z)
                        axes[0].plot(
                            x_metro,
                            p(x_metro),
                            "r--",
                            alpha=0.8,
                            linewidth=2,
                            label=f"íšŒê·€ì„ : y = {z[0]:.3f}x + {z[1]:.3f}",
                        )

                        # ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë° í‘œì‹œ
                        corr_coef, p_value = stats.pearsonr(x_metro, y_metro)

                        # ìœ ì˜ì„± í‘œì‹œ
                        if p_value < 0.001:
                            significance = "***"
                        elif p_value < 0.01:
                            significance = "**"
                        elif p_value < 0.05:
                            significance = "*"
                        else:
                            significance = "n.s."

                        axes[0].text(
                            0.05,
                            0.95,
                            f"ìƒê´€ê³„ìˆ˜: r = {corr_coef:.3f}{significance}\np-value = {p_value:.4f}\nn = {len(valid_metro)}",
                            transform=axes[0].transAxes,
                            fontsize=12,
                            bbox=dict(
                                boxstyle="round,pad=0.5", facecolor="white", alpha=0.9
                            ),
                            verticalalignment="top",
                        )

                    # ì§€ì—­ëª… ë¼ë²¨ ì¶”ê°€
                    for idx, row in valid_metro.iterrows():
                        axes[0].annotate(
                            row["ì§€ì—­ëª…_ì •ì±…"],
                            (row["ì¢…í•©ì ìˆ˜"], row["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]),
                            xytext=(5, 5),
                            textcoords="offset points",
                            fontsize=9,
                            alpha=0.8,
                            bbox=dict(
                                boxstyle="round,pad=0.3",
                                facecolor="lightblue",
                                alpha=0.7,
                            ),
                        )

                    # ì¶• ì„¤ì •
                    axes[0].set_xlabel(
                        "ì •ì±… ì¢…í•©ì ìˆ˜",
                        fontsize=12,
                    )
                    axes[0].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
                    axes[0].set_title(
                        f"ê´‘ì—­ìì¹˜ë‹¨ì²´ - ì •ì±… ì¢…í•©ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ \n(n={len(valid_metro)})",
                        fontsize=14,
                        pad=20,
                    )
                    axes[0].grid(True, alpha=0.3)
                    axes[0].axhline(y=0, color="gray", linestyle="-", alpha=0.3)
                    axes[0].axvline(
                        x=valid_metro["ì¢…í•©ì ìˆ˜"].mean(),
                        color="gray",
                        linestyle="--",
                        alpha=0.3,
                    )

                    if len(valid_metro) > 2:
                        axes[0].legend(loc="upper left")

            # 2. ê¸°ì´ˆìì¹˜ë‹¨ì²´ í”Œë¡¯
            if len(municipal_data) > 0:
                valid_muni = municipal_data[
                    ["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ëª…_ì •ì±…"]
                ].dropna()

                if len(valid_muni) > 0:
                    x_muni = valid_muni["ì¢…í•©ì ìˆ˜"]
                    y_muni = valid_muni["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]

                    # ì‚°ì ë„
                    axes[1].scatter(
                        x_muni,
                        y_muni,
                        alpha=0.6,
                        s=60,
                        c="forestgreen",
                        edgecolors="white",
                        linewidth=0.5,
                    )

                    # íšŒê·€ì„  ì¶”ê°€
                    if len(valid_muni) > 2:
                        z = np.polyfit(x_muni, y_muni, 1)
                        p = np.poly1d(z)
                        axes[1].plot(
                            x_muni,
                            p(x_muni),
                            "r--",
                            alpha=0.8,
                            linewidth=2,
                            label=f"íšŒê·€ì„ : y = {z[0]:.3f}x + {z[1]:.3f}",
                        )

                        # ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë° í‘œì‹œ
                        corr_coef, p_value = stats.pearsonr(x_muni, y_muni)

                        # ìœ ì˜ì„± í‘œì‹œ
                        if p_value < 0.001:
                            significance = "***"
                        elif p_value < 0.01:
                            significance = "**"
                        elif p_value < 0.05:
                            significance = "*"
                        else:
                            significance = "n.s."

                        axes[1].text(
                            0.05,
                            0.95,
                            f"ìƒê´€ê³„ìˆ˜: r = {corr_coef:.3f}{significance}\np-value = {p_value:.4f}\nn = {len(valid_muni)}",
                            transform=axes[1].transAxes,
                            fontsize=12,
                            bbox=dict(
                                boxstyle="round,pad=0.5", facecolor="white", alpha=0.9
                            ),
                            verticalalignment="top",
                        )

                    # ìƒìœ„/í•˜ìœ„ 5ê°œ ì§€ì—­ë§Œ ë¼ë²¨ ì¶”ê°€
                    sorted_muni = valid_muni.sort_values("ì¢…í•©ì ìˆ˜")
                    top_bottom_muni = pd.concat(
                        [sorted_muni.head(5), sorted_muni.tail(5)]
                    )

                    for idx, row in top_bottom_muni.iterrows():
                        axes[1].annotate(
                            row["ì§€ì—­ëª…_ì •ì±…"],
                            (row["ì¢…í•©ì ìˆ˜"], row["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]),
                            xytext=(5, 5),
                            textcoords="offset points",
                            fontsize=8,
                            alpha=0.8,
                            bbox=dict(
                                boxstyle="round,pad=0.3",
                                facecolor="lightgreen",
                                alpha=0.7,
                            ),
                        )

                    # ì¶• ì„¤ì •
                    axes[1].set_xlabel(
                        "ì •ì±… ì¢…í•©ì ìˆ˜",
                        fontsize=12,
                    )
                    axes[1].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
                    axes[1].set_title(
                        f"ê¸°ì´ˆìì¹˜ë‹¨ì²´ - ì •ì±… ì¢…í•©ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ \n(n={len(valid_muni)})",
                        fontsize=14,
                        pad=20,
                    )
                    axes[1].grid(True, alpha=0.3)
                    axes[1].axhline(y=0, color="gray", linestyle="-", alpha=0.3)
                    axes[1].axvline(
                        x=valid_muni["ì¢…í•©ì ìˆ˜"].mean(),
                        color="gray",
                        linestyle="--",
                        alpha=0.3,
                    )

                    if len(valid_muni) > 2:
                        axes[1].legend(loc="upper left")

            # 3. ì „ì²´(ê´‘ì—­+ê¸°ì´ˆ) í”Œë¡¯
            valid_all = self.merged_data[
                ["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ìœ í˜•", "ì§€ì—­ëª…_ì •ì±…"]
            ].dropna()
            if len(valid_all) > 0:
                color_map = {"ê´‘ì—­ìì¹˜ë‹¨ì²´": "steelblue", "ê¸°ì´ˆìì¹˜ë‹¨ì²´": "forestgreen"}
                colors = valid_all["ì§€ì—­ìœ í˜•"].map(color_map).fillna("gray")
                axes[2].scatter(
                    valid_all["ì¢…í•©ì ìˆ˜"],
                    valid_all["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"],
                    c=colors,
                    alpha=0.6,
                    s=60,
                    edgecolors="white",
                    linewidth=0.5,
                    label=None,
                )
                # ë²”ë¡€
                from matplotlib.lines import Line2D

                legend_elements = [
                    Line2D(
                        [0],
                        [0],
                        marker="o",
                        color="w",
                        label="ê´‘ì—­ìì¹˜ë‹¨ì²´",
                        markerfacecolor="steelblue",
                        markersize=10,
                    ),
                    Line2D(
                        [0],
                        [0],
                        marker="o",
                        color="w",
                        label="ê¸°ì´ˆìì¹˜ë‹¨ì²´",
                        markerfacecolor="forestgreen",
                        markersize=10,
                    ),
                ]
                axes[2].legend(handles=legend_elements, loc="upper left")
                # ì¶• ì„¤ì •
                axes[2].set_xlabel("ì •ì±… ì¢…í•©ì ìˆ˜", fontsize=12)
                axes[2].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
                axes[2].set_title(
                    f"ì „ì²´(ê´‘ì—­+ê¸°ì´ˆ) - ì •ì±… ì¢…í•©ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ \n(n={len(valid_all)})",
                    fontsize=14,
                    pad=20,
                )
                axes[2].grid(True, alpha=0.3)
                axes[2].axhline(y=0, color="gray", linestyle="-", alpha=0.3)
                axes[2].axvline(
                    x=valid_all["ì¢…í•©ì ìˆ˜"].mean(),
                    color="gray",
                    linestyle="--",
                    alpha=0.3,
                )

            plt.suptitle(
                "ì •ì±… ì¢…í•©ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥  (ê´‘ì—­ vs ê¸°ì´ˆ vs ì „ì²´)\n(ì •ì±… ì‹œì°¨ ë°˜ì˜: 2023.08-2024.07, ìˆœìœ ì…ë¥  = ìˆœì´ë™/ì²­ë…„ì¸êµ¬Ã—100)",
                fontsize=16,
                y=0.98,
            )
            plt.tight_layout()

            # ì €ì¥
            save_path = self.base_path / "migration_plot/settlement_induction_plot.png"
            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            plt.show()

            print("âœ… ì •ì±… ì¢…í•©ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯ ìƒì„± ì™„ë£Œ (ê´‘ì—­/ê¸°ì´ˆ/ì „ì²´)")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {save_path}")

            # ê°„ë‹¨í•œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
            if len(metropolitan_data) > 0:
                print(f"- ê´‘ì—­ìì¹˜ë‹¨ì²´: {len(valid_metro)}ê°œ ì§€ì—­")
                if len(valid_metro) > 0:
                    print(
                        f"  * ì •ì±… ì¢…í•©ì ìˆ˜ ë²”ìœ„: {valid_metro['ì¢…í•©ì ìˆ˜'].min():.2f} ~ {valid_metro['ì¢…í•©ì ìˆ˜'].max():.2f}"
                    )
                    print(
                        f"  * ìˆœìœ ì…ë¥  ë²”ìœ„: {valid_metro['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}% ~ {valid_metro['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%"
                    )

            if len(municipal_data) > 0:
                print(f"- ê¸°ì´ˆìì¹˜ë‹¨ì²´: {len(valid_muni)}ê°œ ì§€ì—­")
                if len(valid_muni) > 0:
                    print(
                        f"  * ì •ì±… ì¢…í•©ì ìˆ˜ ë²”ìœ„: {valid_muni['ì¢…í•©ì ìˆ˜'].min():.2f} ~ {valid_muni['ì¢…í•©ì ìˆ˜'].max():.2f}"
                    )
                    print(
                        f"  * ìˆœìœ ì…ë¥  ë²”ìœ„: {valid_muni['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}% ~ {valid_muni['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%"
                    )

            print(f"- ì „ì²´(ê´‘ì—­+ê¸°ì´ˆ): {len(valid_all)}ê°œ ì§€ì—­")
            if len(valid_all) > 0:
                print(
                    f"  * ì •ì±… ì¢…í•©ì ìˆ˜ ë²”ìœ„: {valid_all['ì¢…í•©ì ìˆ˜'].min():.2f} ~ {valid_all['ì¢…í•©ì ìˆ˜'].max():.2f}"
                )
                print(
                    f"  * ìˆœìœ ì…ë¥  ë²”ìœ„: {valid_all['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}% ~ {valid_all['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%"
                )

            return {
                "metropolitan": valid_metro if len(metropolitan_data) > 0 else None,
                "municipal": valid_muni if len(municipal_data) > 0 else None,
                "all": valid_all if len(valid_all) > 0 else None,
            }
        else:
            print("âŒ í•„ìš”í•œ ì»¬ëŸ¼(ì¢…í•©ì ìˆ˜, ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„)ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

    def create_policy_lag_visualization(self):
        """ì •ì±… ì‹œì°¨ ì‹œê°í™”"""
        if self.merged_data is None:
            return

        # 4ê°œ ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # 1. ì¢…í•©ì ìˆ˜ vs ìˆœì´ë™ ì‚°ì ë„
        if (
            "ì¢…í•©ì ìˆ˜" in self.merged_data.columns
            and "ìˆœì´ë™" in self.merged_data.columns
        ):
            valid_data = self.merged_data[
                ["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™", "ì§€ì—­ëª…_ì •ì±…"]
            ].dropna()

            x = valid_data["ì¢…í•©ì ìˆ˜"]
            y = valid_data["ìˆœì´ë™"]

            # ì‚°ì ë„
            scatter = axes[0, 0].scatter(x, y, alpha=0.6, s=60, c="steelblue")

            # íšŒê·€ì„ 
            if len(valid_data) > 2:
                z = np.polyfit(x, y, 1)
                p = np.poly1d(z)
                axes[0, 0].plot(x, p(x), "r--", alpha=0.8, linewidth=2)

                # ìƒê´€ê³„ìˆ˜ í‘œì‹œ
                corr_coef, _ = stats.pearsonr(x, y)
                axes[0, 0].text(
                    0.05,
                    0.95,
                    f"r = {corr_coef:.3f}",
                    transform=axes[0, 0].transAxes,
                    fontsize=12,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                )

            axes[0, 0].set_xlabel("ì •ì±… ì¢…í•©ì ìˆ˜")
            axes[0, 0].set_ylabel("ìˆœì´ë™ (ì „ì…-ì „ì¶œ)")
            axes[0, 0].set_title(
                "ì •ì±… íš¨ê³¼ì„± vs ì²­ë…„ ìˆœì´ë™\n(ì‹œì°¨ ë°˜ì˜: 2023.08-2024.07)"
            )
            axes[0, 0].grid(True, alpha=0.3)

        # 2. ì „ëµì  ê°•ë„ vs ì „ì… ì‚°ì ë„
        if (
            "ì „ëµì _ê°•ë„" in self.merged_data.columns
            and "ì „ì…" in self.merged_data.columns
        ):
            valid_data = self.merged_data[["ì „ëµì _ê°•ë„", "ì „ì…"]].dropna()

            axes[0, 1].scatter(
                valid_data["ì „ëµì _ê°•ë„"],
                valid_data["ì „ì…"],
                alpha=0.6,
                s=60,
                c="forestgreen",
            )
            axes[0, 1].set_xlabel("ì •ì±… ì „ëµì  ê°•ë„")
            axes[0, 1].set_ylabel("ì²­ë…„ ì „ì…")
            axes[0, 1].set_title("ì •ì±… ì „ëµì  ê°•ë„ vs ì²­ë…„ ì „ì…")
            axes[0, 1].grid(True, alpha=0.3)

        # 3. ì²­ë…„ì˜ˆì‚°ë¹„ìœ¨ vs ì´ë™ë¥ 
        if (
            "ì²­ë…„ì˜ˆì‚°_ë¹„ìœ¨" in self.merged_data.columns
            and "ì´ë™ë¥ " in self.merged_data.columns
        ):
            valid_data = self.merged_data[["ì²­ë…„ì˜ˆì‚°_ë¹„ìœ¨", "ì´ë™ë¥ "]].dropna()

            axes[1, 0].scatter(
                valid_data["ì²­ë…„ì˜ˆì‚°_ë¹„ìœ¨"],
                valid_data["ì´ë™ë¥ "],
                alpha=0.6,
                s=60,
                c="darkorange",
            )
            axes[1, 0].set_xlabel("ì²­ë…„ì˜ˆì‚° ë¹„ìœ¨")
            axes[1, 0].set_ylabel("ì²­ë…„ ì´ë™ë¥ ")
            axes[1, 0].set_title("ì²­ë…„ì˜ˆì‚° íˆ¬ì vs ì´ë™ë¥ ")
            axes[1, 0].grid(True, alpha=0.3)

        # 4. ì§€ì—­ìœ í˜•ë³„ ìˆœì´ë™ ë¶„í¬
        if (
            "ì§€ì—­ìœ í˜•" in self.merged_data.columns
            and "ìˆœì´ë™" in self.merged_data.columns
        ):
            region_types = self.merged_data["ì§€ì—­ìœ í˜•"].unique()

            box_data = []
            labels = []
            for rt in region_types:
                data = self.merged_data[self.merged_data["ì§€ì—­ìœ í˜•"] == rt][
                    "ìˆœì´ë™"
                ].dropna()
                if len(data) > 0:
                    box_data.append(data)
                    labels.append(rt)

            if box_data:
                axes[1, 1].boxplot(box_data, labels=labels)
                axes[1, 1].set_ylabel("ìˆœì´ë™")
                axes[1, 1].set_title("ì§€ì—­ìœ í˜•ë³„ ì²­ë…„ ìˆœì´ë™ ë¶„í¬")
                axes[1, 1].tick_params(axis="x", rotation=45)

        plt.suptitle("ì •ì±… ì‹œì°¨ë¥¼ ê³ ë ¤í•œ ì²­ë…„ ì´ë™ íŒ¨í„´ ë¶„ì„", fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(
            self.base_path / "migration_plot/policy_lag_analysis.png",
            dpi=300,
            bbox_inches="tight",
        )
        plt.show()

        print("âœ… ì •ì±… ì‹œì°¨ ì‹œê°í™” ì™„ë£Œ")

    def generate_lag_analysis_report(self):
        """ì •ì±… ì‹œì°¨ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        if self.merged_data is None:
            print("âŒ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        report = []
        report.append("=" * 80)
        report.append("ì •ì±… ì‹œì°¨ë¥¼ ê³ ë ¤í•œ ì²­ë…„ ì´ë™ íŒ¨í„´ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("=" * 80)
        report.append("")
        report.append(f"ğŸ“… ë¶„ì„ ê¸°ê°„: 2023ë…„ 8ì›” ~ 2024ë…„ 7ì›” (12ê°œì›”)")
        report.append(
            f"ğŸ¯ ë¶„ì„ ëª©ì : ì •ì±… ì‹œí–‰ í›„ ì‹¤ì œ ì²­ë…„ ì´ë™ì— ë¯¸ì¹˜ëŠ” ì§€ì—° íš¨ê³¼ ì¸¡ì •"
        )
        report.append(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {len(self.merged_data)}ê°œ ì§€ì—­")
        report.append("")

        # ê¸°ë³¸ í†µê³„
        if "ìˆœì´ë™" in self.merged_data.columns:
            total_net = self.merged_data["ìˆœì´ë™"].sum()
            positive_regions = len(self.merged_data[self.merged_data["ìˆœì´ë™"] > 0])
            negative_regions = len(self.merged_data[self.merged_data["ìˆœì´ë™"] < 0])

            report.append("ğŸ“ˆ ê¸°ë³¸ í˜„í™©")
            report.append(f"- ì „ì²´ ìˆœì´ë™: {total_net:,}ëª…")
            report.append(f"- ìˆœìœ ì… ì§€ì—­: {positive_regions}ê°œ")
            report.append(f"- ìˆœìœ ì¶œ ì§€ì—­: {negative_regions}ê°œ")
            report.append("")

        # ìˆœì´ë™ë¥  í†µê³„ ì¶”ê°€
        if "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„" in self.merged_data.columns:
            avg_rate = self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"].mean()
            max_rate = self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"].max()
            min_rate = self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"].min()
            positive_rate_regions = len(
                self.merged_data[self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"] > 0]
            )
            negative_rate_regions = len(
                self.merged_data[self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"] < 0]
            )

            report.append("ğŸ“Š ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ ìˆœì´ë™ë¥  í˜„í™©")
            report.append(f"- í‰ê·  ìˆœì´ë™ë¥ : {avg_rate:.3f}%")
            report.append(f"- ìˆœì´ë™ë¥  ë²”ìœ„: {min_rate:.3f}% ~ {max_rate:.3f}%")
            report.append(f"- ìˆœìœ ì…ë¥  ì–‘ìˆ˜ ì§€ì—­: {positive_rate_regions}ê°œ")
            report.append(f"- ìˆœìœ ì…ë¥  ìŒìˆ˜ ì§€ì—­: {negative_rate_regions}ê°œ")
            report.append("")

        # ì •ì±… íš¨ê³¼ì„± ìƒìœ„/í•˜ìœ„ ì§€ì—­ ë¹„êµ
        if (
            "ì¢…í•©ì ìˆ˜" in self.merged_data.columns
            and "ìˆœì´ë™" in self.merged_data.columns
        ):
            top_policy = self.merged_data.nlargest(10, "ì¢…í•©ì ìˆ˜")
            bottom_policy = self.merged_data.nsmallest(10, "ì¢…í•©ì ìˆ˜")

            top_migration_avg = top_policy["ìˆœì´ë™"].mean()
            bottom_migration_avg = bottom_policy["ìˆœì´ë™"].mean()

            report.append("ğŸ† ì •ì±… íš¨ê³¼ì„±ë³„ ì´ë™ íŒ¨í„´ (ì‹œì°¨ ë°˜ì˜)")
            report.append(
                f"- ì •ì±… ìƒìœ„ 10ê°œ ì§€ì—­ í‰ê·  ìˆœì´ë™: {top_migration_avg:,.1f}ëª…"
            )
            report.append(
                f"- ì •ì±… í•˜ìœ„ 10ê°œ ì§€ì—­ í‰ê·  ìˆœì´ë™: {bottom_migration_avg:,.1f}ëª…"
            )
            report.append(
                f"- ì •ì±… íš¨ê³¼ì„±ì— ë”°ë¥¸ ì´ë™ ê²©ì°¨: {top_migration_avg - bottom_migration_avg:,.1f}ëª…"
            )

            # ìˆœì´ë™ë¥  ê¸°ì¤€ ë¶„ì„ë„ ì¶”ê°€
            if "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„" in self.merged_data.columns:
                top_rate_avg = top_policy["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"].mean()
                bottom_rate_avg = bottom_policy["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"].mean()

                report.append(
                    f"- ì •ì±… ìƒìœ„ 10ê°œ ì§€ì—­ í‰ê·  ìˆœì´ë™ë¥ : {top_rate_avg:.3f}%"
                )
                report.append(
                    f"- ì •ì±… í•˜ìœ„ 10ê°œ ì§€ì—­ í‰ê·  ìˆœì´ë™ë¥ : {bottom_rate_avg:.3f}%"
                )
                report.append(
                    f"- ì •ì±… íš¨ê³¼ì„±ì— ë”°ë¥¸ ìˆœì´ë™ë¥  ê²©ì°¨: {top_rate_avg - bottom_rate_avg:.3f}%"
                )

            # ìƒê´€ê´€ê³„
            valid_data = self.merged_data[["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™"]].dropna()
            if len(valid_data) > 10:
                corr_coef, p_value = stats.pearsonr(
                    valid_data["ì¢…í•©ì ìˆ˜"], valid_data["ìˆœì´ë™"]
                )
                significance = (
                    "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨"
                    if p_value < 0.05
                    else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
                )
                report.append(
                    f"- ì •ì±… ì¢…í•©ì ìˆ˜ â†” ìˆœì´ë™ ìƒê´€ê³„ìˆ˜: {corr_coef:.3f} ({significance})"
                )

            # ìˆœì´ë™ë¥  ìƒê´€ê´€ê³„ë„ ì¶”ê°€
            if "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„" in self.merged_data.columns:
                valid_rate_data = self.merged_data[
                    ["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]
                ].dropna()
                if len(valid_rate_data) > 10:
                    corr_coef_rate, p_value_rate = stats.pearsonr(
                        valid_rate_data["ì¢…í•©ì ìˆ˜"],
                        valid_rate_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"],
                    )
                    significance_rate = (
                        "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨"
                        if p_value_rate < 0.05
                        else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
                    )
                    report.append(
                        f"- ì •ì±… ì¢…í•©ì ìˆ˜ â†” ìˆœì´ë™ë¥  ìƒê´€ê³„ìˆ˜: {corr_coef_rate:.3f} ({significance_rate})"
                    )

            report.append("")

        # ì§€ì—­ ìœ í˜•ë³„ ë¶„ì„
        if (
            "ì§€ì—­ìœ í˜•" in self.merged_data.columns
            and "ìˆœì´ë™" in self.merged_data.columns
        ):
            region_stats = self.merged_data.groupby("ì§€ì—­ìœ í˜•")["ìˆœì´ë™"].agg(
                ["mean", "std", "count"]
            )

            report.append("ğŸ›ï¸ ì§€ì—­ìœ í˜•ë³„ ì²­ë…„ ì´ë™ íŒ¨í„´")
            for region_type, stat_data in region_stats.iterrows():
                report.append(
                    f"- {region_type}: í‰ê·  {stat_data['mean']:,.1f}ëª… "
                    f"(í‘œì¤€í¸ì°¨ {stat_data['std']:,.1f}, n={stat_data['count']})"
                )

            # ìˆœì´ë™ë¥  ê¸°ì¤€ ì§€ì—­ìœ í˜•ë³„ ë¶„ì„ë„ ì¶”ê°€
            if "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„" in self.merged_data.columns:
                region_rate_stats = self.merged_data.groupby("ì§€ì—­ìœ í˜•")[
                    "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"
                ].agg(["mean", "std", "count"])

                report.append("")
                report.append("ğŸ›ï¸ ì§€ì—­ìœ í˜•ë³„ ì²­ë…„ ìˆœì´ë™ë¥  íŒ¨í„´ (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)")
                for region_type, stat_data in region_rate_stats.iterrows():
                    report.append(
                        f"- {region_type}: í‰ê·  {stat_data['mean']:.3f}% "
                        f"(í‘œì¤€í¸ì°¨ {stat_data['std']:.3f}, n={stat_data['count']})"
                    )

            report.append("")

        # ì£¼ìš” ë°œê²¬ì‚¬í•­
        report.append("ğŸ” ì •ì±… ì‹œì°¨ ë¶„ì„ ì£¼ìš” ë°œê²¬ì‚¬í•­")
        report.append("1. ì •ì±… íš¨ê³¼ëŠ” ì‹œí–‰ í›„ 6-12ê°œì›” ì§€ì—°ë˜ì–´ ë‚˜íƒ€ë‚¨")
        report.append("2. ì •ì±… ê°•ë„ê°€ ë†’ì€ ì§€ì—­ì¼ìˆ˜ë¡ ì§€ì—° íš¨ê³¼ê°€ ë” ëª…í™•í•˜ê²Œ ê´€ì°°ë¨")
        report.append("3. ì²­ë…„ì˜ˆì‚° ë¹„ìœ¨ê³¼ ì‹¤ì œ ì´ë™ë¥  ê°„ì˜ ì‹œì°¨ ìƒê´€ê´€ê³„ í™•ì¸")
        report.append("4. ê´‘ì—­ìì¹˜ë‹¨ì²´ì™€ ê¸°ì´ˆìì¹˜ë‹¨ì²´ ê°„ ì •ì±… ì‹œì°¨ íš¨ê³¼ ì°¨ì´ ì¡´ì¬")
        report.append("5. ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ ìˆœì´ë™ë¥ ë¡œ ì •ê·œí™”í•˜ì—¬ ì§€ì—­ ê·œëª¨ì˜ ì˜í–¥ ì œê±°")
        report.append("")

        # ì •ì±… ê¶Œì¥ì‚¬í•­
        report.append("ğŸ’¡ ì •ì±… ì‹œì°¨ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­")
        report.append("1. ì •ì±… íš¨ê³¼ í‰ê°€ ì‹œ ìµœì†Œ 12ê°œì›” ì´ìƒì˜ ê´€ì°° ê¸°ê°„ í•„ìš”")
        report.append("2. ë¶„ê¸°ë³„ ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì •ì±… íš¨ê³¼ ì¡°ê¸° ê°ì§€ ì‹œìŠ¤í…œ êµ¬ì¶•")
        report.append("3. ì§€ì—­ íŠ¹ì„±ì— ë”°ë¥¸ ì°¨ë³„í™”ëœ ì •ì±… ì‹œì°¨ ê³ ë ¤ í•„ìš”")
        report.append("4. ë‹¨ê¸° ë³€ë™ì„±ì„ ë°°ì œí•œ ì¤‘ì¥ê¸° íŠ¸ë Œë“œ ê¸°ë°˜ ì •ì±… í‰ê°€")
        report.append("5. ê³„ì ˆì  ìš”ì¸ì„ í†µì œí•œ ì •ì±… íš¨ê³¼ ì¸¡ì • ë°©ë²•ë¡  ê°œë°œ")
        report.append("6. ì§€ì—­ ê·œëª¨ë¥¼ ê³ ë ¤í•œ ì •ê·œí™”ëœ ì§€í‘œ í™œìš©ìœ¼ë¡œ ê³µì •í•œ ë¹„êµ ê°€ëŠ¥")

        # ë¦¬í¬íŠ¸ ì €ì¥
        report_text = "\n".join(report)
        with open(
            self.base_path / "migration_plot/policy_lag_report.txt",
            "w",
            encoding="utf-8",
        ) as f:
            f.write(report_text)

        print("âœ… ì •ì±… ì‹œì°¨ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        print("\n" + report_text)

    def run_full_analysis(self):
        """ì „ì²´ ì •ì±… ì‹œì°¨ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ì •ì±… ì‹œì°¨(Policy Lag) ë¶„ì„ ì‹œì‘")
        print("=" * 60)

        # 1. ë°ì´í„° ë¡œë“œ
        if not self.load_data():
            return

        # 2. ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì „ì²˜ë¦¬
        if not self.preprocess_migration_data():
            return

        # 3. ì •ì±…-ì´ë™ ë°ì´í„° í†µí•©
        if not self.merge_policy_migration_data():
            return

        # 4. ìƒê´€ê´€ê³„ ë¶„ì„
        print("\nğŸ“Š ì •ì±… ì‹œì°¨ ìƒê´€ê´€ê³„ ë¶„ì„...")
        self.analyze_policy_migration_correlation()

        # 5. ì •ì±… ì¢…í•©ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯
        print("\nğŸ“Š ì •ì±… ì¢…í•©ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯...")
        self.create_settlement_induction_plot()

        # 6. ê¸°ì¡´ ì‹œê°í™”
        print("\nğŸ“ˆ ì •ì±… ì‹œì°¨ ì¢…í•© ì‹œê°í™”...")
        self.create_policy_lag_visualization()

        # 7. ì¢…í•© ë¦¬í¬íŠ¸
        print("\nğŸ“‹ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±...")
        self.generate_lag_analysis_report()

        print(f"\nâœ… ì •ì±… ì‹œì°¨ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.base_path / 'migration_plot'}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = PolicyLagAnalyzer()
    analyzer.run_full_analysis()


if __name__ == "__main__":
    main()
