"""
eval-4 ê²°ê³¼ë¥¼ ì‚¬ìš©í•œ ì •ì±… ì‹œì°¨ ì²­ë…„ ì´ë™ ë¶„ì„ ëª¨ë“ˆ
==================================================

ì´ ëª¨ë“ˆì€ eval-4 ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ì±… ì‹œí–‰ê³¼ ì²­ë…„ ì¸êµ¬ ì´ë™ ê°„ì˜ ì‹œê°„ì°¨ë¥¼ ê³ ë ¤í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
- ê´‘ì—­ìì¹˜ë‹¨ì²´: ì¢…í•©ì ìˆ˜ ì‚¬ìš©
- ê¸°ì´ˆìì¹˜ë‹¨ì²´: ìµœì¢…_ì—°ê³„ì ìˆ˜ ì‚¬ìš© (ê´‘ì—­ì—°ê³„ ê³ ë ¤)
- ë¶„ì„ ê¸°ê°„: 2023ë…„ 8ì›” ~ 2024ë…„ 7ì›” (12ê°œì›”)
"""

import os
import warnings
from pathlib import Path

import matplotlib

matplotlib.use("Agg")  # GUI ì—†ì´ íŒŒì¼ ì €ì¥
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats

warnings.filterwarnings("ignore")

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams["font.family"] = ["AppleGothic", "Malgun Gothic", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False


class PolicyLagAnalyzerEval4:
    """eval-4 ê²°ê³¼ë¥¼ ì‚¬ìš©í•œ ì •ì±… ì‹œì°¨ ì²­ë…„ ì´ë™ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, base_path=None):
        if base_path is None:
            self.base_path = Path(__file__).parent.parent
        else:
            self.base_path = Path(base_path)

        self.policy_data = None
        self.migration_data = None
        self.analysis_period_data = None
        self.merged_data = None

        # ë¶„ì„ ê¸°ê°„ ì„¤ì • (2023ë…„ 8ì›” ~ 2024ë…„ 7ì›”)
        self.start_year_month = 202308
        self.end_year_month = 202407

        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.result_dir = self.base_path / "migration_plot/eval-4_result"
        os.makedirs(self.result_dir, exist_ok=True)

        print(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {self.start_year_month} ~ {self.end_year_month}")
        print(f"ğŸ”— ì‚¬ìš© ë°ì´í„°: eval-4 ê²°ê³¼ (ê´‘ì—­=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆ=ìµœì¢…_ì—°ê³„ì ìˆ˜)")

    def load_data(self):
        """eval-4 ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        try:
            # ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ
            metropolitan_policy_file = (
                self.base_path
                / "data/policy_eval/eval-4_result/ê´‘ì—­_ì²­ë…„ì •ì±…_ì¢…í•©í‰ê°€ê²°ê³¼.csv"
            )

            # ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ (eval-4 ê²°ê³¼ ì‚¬ìš©)
            municipal_policy_file = (
                self.base_path
                / "data/policy_eval/eval-4_result/ê¸°ì´ˆ_ìµœì¢…í‰ê°€ê²°ê³¼(ê´‘ì—­ì—°ê³„).csv"
            )

            policy_data_list = []

            print(f"ê´‘ì—­ íŒŒì¼ ê²½ë¡œ: {metropolitan_policy_file}")
            print(f"ê¸°ì´ˆ íŒŒì¼ ê²½ë¡œ: {municipal_policy_file}")
            print(f"ê´‘ì—­ íŒŒì¼ ì¡´ì¬: {metropolitan_policy_file.exists()}")
            print(f"ê¸°ì´ˆ íŒŒì¼ ì¡´ì¬: {municipal_policy_file.exists()}")

            # ê´‘ì—­ìì¹˜ë‹¨ì²´ ë°ì´í„° ë¡œë“œ
            if metropolitan_policy_file.exists():
                metro_data = pd.read_csv(metropolitan_policy_file, encoding="utf-8-sig")
                metro_data["ì§€ì—­ìœ í˜•"] = "ê´‘ì—­ìì¹˜ë‹¨ì²´"
                metro_data["ì ìˆ˜_ì»¬ëŸ¼"] = "ì¢…í•©ì ìˆ˜"
                metro_data["ì‚¬ìš©_ì ìˆ˜"] = metro_data["ì¢…í•©ì ìˆ˜"]
                print(
                    f"âœ… ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ: {len(metro_data)}ê°œ ì§€ì—­ (ì¢…í•©ì ìˆ˜ ì‚¬ìš©)"
                )
                policy_data_list.append(metro_data)
            else:
                print("âŒ ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ê¸°ì´ˆìì¹˜ë‹¨ì²´ ë°ì´í„° ë¡œë“œ (ìµœì¢…_ì—°ê³„ì ìˆ˜ ì‚¬ìš©)
            if municipal_policy_file.exists():
                muni_data = pd.read_csv(municipal_policy_file, encoding="utf-8-sig")
                muni_data["ì§€ì—­ìœ í˜•"] = "ê¸°ì´ˆìì¹˜ë‹¨ì²´"
                muni_data["ì ìˆ˜_ì»¬ëŸ¼"] = "ìµœì¢…_ì—°ê³„ì ìˆ˜"
                muni_data["ì‚¬ìš©_ì ìˆ˜"] = muni_data["ìµœì¢…_ì—°ê³„ì ìˆ˜"]

                # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
                required_cols = ["ì „ëµì _ê°•ë„", "ì²­ë…„ì¸êµ¬", "ì „ì²´ì¸êµ¬"]
                for col in required_cols:
                    if col not in muni_data.columns:
                        if col == "ì „ëµì _ê°•ë„":
                            muni_data[col] = muni_data.get("ì „ëµì _ê°•ë„", 0)
                        elif col == "ì²­ë…„ì¸êµ¬":
                            muni_data[col] = 50000  # ê¸°ë³¸ê°’
                        elif col == "ì „ì²´ì¸êµ¬":
                            muni_data[col] = 200000  # ê¸°ë³¸ê°’

                print(
                    f"âœ… ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ: {len(muni_data)}ê°œ ì§€ì—­ (ìµœì¢…_ì—°ê³„ì ìˆ˜ ì‚¬ìš©)"
                )
                policy_data_list.append(muni_data)
            else:
                print("âŒ ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            if not policy_data_list:
                print("âŒ ì •ì±… ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False

            # ë‘ ë°ì´í„°ë¥¼ í•©ì¹˜ê¸°
            self.policy_data = pd.concat(policy_data_list, ignore_index=True)
            print(f"âœ… ì „ì²´ ì •ì±… ë°ì´í„° í†µí•©: {len(self.policy_data)}ê°œ ì§€ì—­")

            # ê´‘ì—­/ê¸°ì´ˆ êµ¬ë¶„ì„ ìœ„í•œ ë°ì´í„° ì €ì¥
            self.metropolitan_data = (
                metro_data if metropolitan_policy_file.exists() else None
            )
            self.municipal_data = muni_data if municipal_policy_file.exists() else None

            return self.load_migration_data()

        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    def load_migration_data(self):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        migration_dir = self.base_path / "data/migration/ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰_consolidated"

        if not migration_dir.exists():
            print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ë“¤ ì°¾ê¸°
        target_files = []
        current_ym = self.start_year_month

        while current_ym <= self.end_year_month:
            file_path = migration_dir / f"youth_total_migration_{current_ym}.csv"
            if file_path.exists():
                target_files.append(file_path)
                print(f"   ğŸ“… {current_ym} ë°ì´í„° ë°œê²¬")

            # ë‹¤ìŒ ì›”ë¡œ ì¦ê°€
            current_month = current_ym % 100
            current_year = current_ym // 100

            if current_month == 12:
                current_ym = (current_year + 1) * 100 + 1
            else:
                current_ym = current_year * 100 + (current_month + 1)

        if not target_files:
            print("âŒ ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        print(f"âœ… ì´ {len(target_files)}ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ë°œê²¬")
        return True

    def preprocess_migration_data(self):
        """íŒŒì¼ë³„ë¡œ ê° ì§€ì—­ì˜ ì»¬ëŸ¼í•©(ì „ì…), rowí•©(ì „ì¶œ) ëˆ„ì  ë°©ì‹ìœ¼ë¡œ ìˆœì´ë™ ê³„ì‚°"""
        migration_dir = self.base_path / "data/migration/ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰_consolidated"

        # ë¶„ì„ ê¸°ê°„ íŒŒì¼ ëª©ë¡
        target_files = []
        current_ym = self.start_year_month
        while current_ym <= self.end_year_month:
            file_path = migration_dir / f"youth_total_migration_{current_ym}.csv"
            if file_path.exists():
                target_files.append(file_path)
            current_month = current_ym % 100
            current_year = current_ym // 100
            if current_month == 12:
                current_ym = (current_year + 1) * 100 + 1
            else:
                current_ym = current_year * 100 + (current_month + 1)

        # ëª¨ë“  ì§€ì—­ëª… ì§‘í•©
        all_regions = set()
        for file in target_files:
            df = pd.read_csv(file, encoding="utf-8-sig")
            all_regions.update(df.columns[1:])  # ì²« ì»¬ëŸ¼ì€ ì§€ì—­ëª…(row)
            all_regions.update(df.iloc[:, 0].unique())
        all_regions = sorted(all_regions)

        # ëˆ„ì ìš© dict
        inflow_dict = {region: 0 for region in all_regions}
        outflow_dict = {region: 0 for region in all_regions}

        # íŒŒì¼ë³„ë¡œ ëˆ„ì 
        for file in target_files:
            df = pd.read_csv(file, encoding="utf-8-sig")
            df = df.fillna(0)
            col_regions = df.columns[1:]
            row_regions = df.iloc[:, 0]

            # ì „ì…: ê° ì§€ì—­ë³„ ì»¬ëŸ¼ í•©
            for region in col_regions:
                inflow_dict[region] += df[region].sum()
            # ì „ì¶œ: ê° ì§€ì—­ë³„ row í•©
            for idx, region in enumerate(row_regions):
                outflow_dict[region] += df.iloc[idx, 1:].sum()

        # ê²°ê³¼ DataFrame
        result = []
        for region in all_regions:
            inflow = inflow_dict[region]
            outflow = outflow_dict[region]
            net = inflow - outflow
            result.append(
                {"ì§€ì—­ëª…": region, "ì „ì…": inflow, "ì „ì¶œ": outflow, "ìˆœì´ë™": net}
            )

        self.analysis_period_data = pd.DataFrame(result)
        print(
            f"âœ… íŒŒì¼ ëˆ„ì  ë°©ì‹ ìˆœì´ë™ ê³„ì‚° ì™„ë£Œ: {len(self.analysis_period_data)}ê°œ ì§€ì—­"
        )
        return True

    def merge_policy_migration_data(self):
        """ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° í†µí•©"""
        if self.policy_data is None or self.analysis_period_data is None:
            print("âŒ ì •ì±… ë°ì´í„°, ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
            return False

        print("ğŸ”— ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë§¤ì¹­ ì¤‘...")

        # ì§€ì—­ëª… ì •ì œ ë° ë§¤ì¹­
        def normalize_region_name(name):
            if pd.isna(name):
                return ""
            return str(name).strip().replace("  ", " ")

        self.policy_data["ì§€ì—­ëª…_ì •ì œ"] = self.policy_data["ì§€ì—­ëª…"].apply(
            normalize_region_name
        )
        self.analysis_period_data["ì§€ì—­ëª…_ì •ì œ"] = self.analysis_period_data[
            "ì§€ì—­ëª…"
        ].apply(normalize_region_name)

        # ì •ì±… + ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë³‘í•©
        self.merged_data = pd.merge(
            self.policy_data,
            self.analysis_period_data,
            left_on="ì§€ì—­ëª…_ì •ì œ",
            right_on="ì§€ì—­ëª…_ì •ì œ",
            how="inner",
            suffixes=("_ì •ì±…", "_ì´ë™"),
        )

        if len(self.merged_data) > 0:
            print(f"âœ… ì„±ê³µì ìœ¼ë¡œ í†µí•©ëœ ì§€ì—­: {len(self.merged_data)}ê°œ")

            # ì²­ë…„ì¸êµ¬ ì»¬ëŸ¼ í™•ì¸ ë° ì²˜ë¦¬
            if "ì²­ë…„ì¸êµ¬" in self.merged_data.columns:
                youth_pop_col = "ì²­ë…„ì¸êµ¬"
            else:
                print("âŒ ì²­ë…„ì¸êµ¬ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False

            # ìˆœì´ë™ë¥  ê³„ì‚° (ì²­ë…„ ì¸êµ¬ ìˆ˜ ëŒ€ë¹„ %)
            self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"] = (
                self.merged_data["ìˆœì´ë™"] / (self.merged_data[youth_pop_col] + 1)
            ) * 100

            # ê²°ê³¼ CSVë¡œ ì €ì¥
            save_path = self.result_dir / "settlement_induction_result_eval4.csv"
            self.merged_data.to_csv(save_path, index=False, encoding="utf-8-sig")
            print(f"âœ… í†µí•© ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: {save_path}")
            return True
        else:
            print("âŒ ë§¤ì¹­ë˜ëŠ” ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

    def create_settlement_induction_plot(self):
        """ì •ì±… ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯ ìƒì„±"""
        if self.merged_data is None:
            print("âŒ í†µí•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì§€ì—­ìœ í˜•ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
        metropolitan_data = self.merged_data[
            self.merged_data["ì§€ì—­ìœ í˜•"] == "ê´‘ì—­ìì¹˜ë‹¨ì²´"
        ].copy()
        municipal_data = self.merged_data[
            self.merged_data["ì§€ì—­ìœ í˜•"] == "ê¸°ì´ˆìì¹˜ë‹¨ì²´"
        ].copy()

        # 3x1 ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, axes = plt.subplots(1, 3, figsize=(24, 8))

        # 1. ê´‘ì—­ìì¹˜ë‹¨ì²´ í”Œë¡¯
        if len(metropolitan_data) > 0 and "ì¢…í•©ì ìˆ˜" in metropolitan_data.columns:
            valid_metro = metropolitan_data[
                ["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ëª…_ì´ë™"]
            ].dropna()

            if len(valid_metro) > 0:
                axes[0].scatter(
                    valid_metro["ì¢…í•©ì ìˆ˜"],
                    valid_metro["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"],
                    alpha=0.7,
                    s=120,
                    c="steelblue",
                    edgecolors="white",
                    linewidth=1,
                )

                # íšŒê·€ì„  ì¶”ê°€
                if len(valid_metro) > 2:
                    z = np.polyfit(
                        valid_metro["ì¢…í•©ì ìˆ˜"], valid_metro["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"], 1
                    )
                    p = np.poly1d(z)
                    axes[0].plot(
                        valid_metro["ì¢…í•©ì ìˆ˜"],
                        p(valid_metro["ì¢…í•©ì ìˆ˜"]),
                        "r--",
                        alpha=0.8,
                        linewidth=2,
                    )

                    # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                    corr_coef, p_value = stats.pearsonr(
                        valid_metro["ì¢…í•©ì ìˆ˜"], valid_metro["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]
                    )
                    axes[0].text(
                        0.05,
                        0.95,
                        f"r = {corr_coef:.3f}\np = {p_value:.3f}\nn = {len(valid_metro)}",
                        transform=axes[0].transAxes,
                        fontsize=10,
                        bbox=dict(
                            boxstyle="round,pad=0.5", facecolor="white", alpha=0.9
                        ),
                    )

                axes[0].set_xlabel("ì •ì±… ì¢…í•©ì ìˆ˜", fontsize=12)
                axes[0].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
                axes[0].set_title(
                    f"ê´‘ì—­ìì¹˜ë‹¨ì²´ - ì •ì±… ì¢…í•©ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ ", fontsize=14
                )
                axes[0].grid(True, alpha=0.3)

        # 2. ê¸°ì´ˆìì¹˜ë‹¨ì²´ í”Œë¡¯
        if len(municipal_data) > 0 and "ìµœì¢…_ì—°ê³„ì ìˆ˜" in municipal_data.columns:
            valid_muni = municipal_data[
                ["ìµœì¢…_ì—°ê³„ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ëª…_ì´ë™"]
            ].dropna()

            if len(valid_muni) > 0:
                axes[1].scatter(
                    valid_muni["ìµœì¢…_ì—°ê³„ì ìˆ˜"],
                    valid_muni["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"],
                    alpha=0.6,
                    s=60,
                    c="forestgreen",
                    edgecolors="white",
                    linewidth=0.5,
                )

                # íšŒê·€ì„  ì¶”ê°€
                if len(valid_muni) > 2:
                    z = np.polyfit(
                        valid_muni["ìµœì¢…_ì—°ê³„ì ìˆ˜"], valid_muni["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"], 1
                    )
                    p = np.poly1d(z)
                    axes[1].plot(
                        valid_muni["ìµœì¢…_ì—°ê³„ì ìˆ˜"],
                        p(valid_muni["ìµœì¢…_ì—°ê³„ì ìˆ˜"]),
                        "r--",
                        alpha=0.8,
                        linewidth=2,
                    )

                    # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                    corr_coef, p_value = stats.pearsonr(
                        valid_muni["ìµœì¢…_ì—°ê³„ì ìˆ˜"], valid_muni["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]
                    )
                    axes[1].text(
                        0.05,
                        0.95,
                        f"r = {corr_coef:.3f}\np = {p_value:.3f}\nn = {len(valid_muni)}",
                        transform=axes[1].transAxes,
                        fontsize=10,
                        bbox=dict(
                            boxstyle="round,pad=0.5", facecolor="white", alpha=0.9
                        ),
                    )

                axes[1].set_xlabel("ìµœì¢… ì—°ê³„ì ìˆ˜ (ê´‘ì—­ì—°ê³„)", fontsize=12)
                axes[1].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
                axes[1].set_title(
                    f"ê¸°ì´ˆìì¹˜ë‹¨ì²´ - ìµœì¢… ì—°ê³„ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ ", fontsize=14
                )
                axes[1].grid(True, alpha=0.3)

        # 3. ì „ì²´(ê´‘ì—­+ê¸°ì´ˆ) í”Œë¡¯
        valid_all = self.merged_data[
            ["ì‚¬ìš©_ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ìœ í˜•", "ì§€ì—­ëª…_ì´ë™"]
        ].dropna()

        if len(valid_all) > 0:
            color_map = {"ê´‘ì—­ìì¹˜ë‹¨ì²´": "steelblue", "ê¸°ì´ˆìì¹˜ë‹¨ì²´": "forestgreen"}
            colors = valid_all["ì§€ì—­ìœ í˜•"].map(color_map).fillna("gray")

            axes[2].scatter(
                valid_all["ì‚¬ìš©_ì ìˆ˜"],
                valid_all["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"],
                c=colors,
                alpha=0.6,
                s=60,
                edgecolors="white",
                linewidth=0.5,
            )

            # íšŒê·€ì„  ì¶”ê°€
            if len(valid_all) > 2:
                z = np.polyfit(
                    valid_all["ì‚¬ìš©_ì ìˆ˜"], valid_all["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"], 1
                )
                p = np.poly1d(z)
                axes[2].plot(
                    valid_all["ì‚¬ìš©_ì ìˆ˜"],
                    p(valid_all["ì‚¬ìš©_ì ìˆ˜"]),
                    "r--",
                    alpha=0.8,
                    linewidth=2,
                )

                # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                corr_coef, p_value = stats.pearsonr(
                    valid_all["ì‚¬ìš©_ì ìˆ˜"], valid_all["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]
                )
                axes[2].text(
                    0.05,
                    0.95,
                    f"ì „ì²´ r = {corr_coef:.3f}\np = {p_value:.3f}\nn = {len(valid_all)}",
                    transform=axes[2].transAxes,
                    fontsize=10,
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="white", alpha=0.9),
                )

            axes[2].set_xlabel(
                "ì •ì±… ì ìˆ˜ (ê´‘ì—­=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆ=ìµœì¢…_ì—°ê³„ì ìˆ˜)", fontsize=12
            )
            axes[2].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
            axes[2].set_title(
                f"ì „ì²´(ê´‘ì—­+ê¸°ì´ˆ) - ì •ì±… ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ ", fontsize=14
            )
            axes[2].grid(True, alpha=0.3)

        plt.suptitle("ì •ì±… ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥  (eval-4)", fontsize=16, y=0.98)
        plt.tight_layout()

        # ì €ì¥
        save_path = self.result_dir / "settlement_induction_plot_eval4.png"
        try:
            plt.savefig(save_path, dpi=300, bbox_inches="tight")
            print(f"âœ… í”Œë¡¯ ì €ì¥ ì„±ê³µ: {save_path}")
        except Exception as e:
            print(f"âŒ í”Œë¡¯ ì €ì¥ ì‹¤íŒ¨: {e}")

        plt.close()

    def run_full_analysis(self):
        """ì „ì²´ ì •ì±… ì‹œì°¨ ë¶„ì„ ì‹¤í–‰ (eval-4 ë²„ì „)"""
        print("ğŸš€ ì •ì±… ì‹œì°¨(Policy Lag) ë¶„ì„ ì‹œì‘ (eval-4)")
        print("=" * 60)

        # 1. ë°ì´í„° ë¡œë“œ
        if not self.load_data():
            return

        # 2. ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì „ì²˜ë¦¬
        if not self.preprocess_migration_data():
            return

        # 3. ì •ì±…-ì´ë™ ë°ì´í„° í†µí•©
        if not self.merge_policy_migration_data():
            return

        # 4. ì •ì±… ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯ (í•µì‹¬)
        print("\nğŸ“Š ì •ì±… ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯...")
        self.create_settlement_induction_plot()

        print(f"\nâœ… ì •ì±… ì‹œì°¨ ë¶„ì„ ì™„ë£Œ (eval-4)!")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.result_dir}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = PolicyLagAnalyzerEval4()
    analyzer.run_full_analysis()


if __name__ == "__main__":
    main()
