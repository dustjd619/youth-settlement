"""
eval-4 ê²°ê³¼ë¥¼ ì‚¬ìš©í•œ ì •ì±… ì‹œì°¨ ì²­ë…„ ì´ë™ ë¶„ì„ ëª¨ë“ˆ
==================================================

ì´ ëª¨ë“ˆì€ eval-4 ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ì±… ì‹œí–‰ê³¼ ì²­ë…„ ì¸êµ¬ ì´ë™ ê°„ì˜ ì‹œê°„ì°¨ë¥¼ ê³ ë ¤í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
- ê´‘ì—­ìì¹˜ë‹¨ì²´: ì¢…í•©ì ìˆ˜ ì‚¬ìš©
- ê¸°ì´ˆìì¹˜ë‹¨ì²´: ìµœì¢…_ì—°ê³„ì ìˆ˜ ì‚¬ìš© (ê´‘ì—­ì—°ê³„ ê³ ë ¤)
- ë¶„ì„ ê¸°ê°„: 2023ë…„ 8ì›” ~ 2024ë…„ 7ì›” (12ê°œì›”)
"""

import warnings
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats

warnings.filterwarnings("ignore")

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams["font.family"] = ["AppleGothic", "Malgun Gothic", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False


class PolicyLagAnalyzerEval4:
    """eval-4 ê²°ê³¼ë¥¼ ì‚¬ìš©í•œ ì •ì±… ì‹œì°¨ ì²­ë…„ ì´ë™ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, base_path=None):
        if base_path is None:
            self.base_path = Path(__file__).parent.parent
        else:
            self.base_path = Path(base_path)

        self.policy_data = None
        self.migration_data = None
        self.analysis_period_data = None
        self.merged_data = None

        # ë¶„ì„ ê¸°ê°„ ì„¤ì • (2023ë…„ 8ì›” ~ 2024ë…„ 7ì›”)
        self.start_year_month = 202308
        self.end_year_month = 202407

        print(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {self.start_year_month} ~ {self.end_year_month}")
        print(f"ğŸ”— ì‚¬ìš© ë°ì´í„°: eval-4 ê²°ê³¼ (ê´‘ì—­=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆ=ìµœì¢…_ì—°ê³„ì ìˆ˜)")

    def load_data(self):
        """eval-4 ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        # ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ
        metropolitan_policy_file = (
            self.base_path
            / "data/policy_eval/eval-4_result/ê´‘ì—­_ì²­ë…„ì •ì±…_ì¢…í•©í‰ê°€ê²°ê³¼.csv"
        )

        # ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ (eval-4 ê²°ê³¼ ì‚¬ìš©)
        municipal_policy_file = (
            self.base_path
            / "data/policy_eval/eval-4_result/ê¸°ì´ˆ_ìµœì¢…í‰ê°€ê²°ê³¼(ê´‘ì—­ì—°ê³„).csv"
        )

        policy_data_list = []

        # ê´‘ì—­ìì¹˜ë‹¨ì²´ ë°ì´í„° ë¡œë“œ
        if metropolitan_policy_file.exists():
            metro_data = pd.read_csv(metropolitan_policy_file, encoding="utf-8-sig")
            metro_data["ì§€ì—­ìœ í˜•"] = "ê´‘ì—­ìì¹˜ë‹¨ì²´"
            metro_data["ì ìˆ˜_ì»¬ëŸ¼"] = "ì¢…í•©ì ìˆ˜"
            metro_data["ì‚¬ìš©_ì ìˆ˜"] = metro_data["ì¢…í•©ì ìˆ˜"]
            print(
                f"âœ… ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ: {len(metro_data)}ê°œ ì§€ì—­ (ì¢…í•©ì ìˆ˜ ì‚¬ìš©)"
            )
            policy_data_list.append(metro_data)
        else:
            print("âŒ ê´‘ì—­ìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ê¸°ì´ˆìì¹˜ë‹¨ì²´ ë°ì´í„° ë¡œë“œ (ìµœì¢…_ì—°ê³„ì ìˆ˜ ì‚¬ìš©)
        if municipal_policy_file.exists():
            muni_data = pd.read_csv(municipal_policy_file, encoding="utf-8-sig")
            muni_data["ì§€ì—­ìœ í˜•"] = "ê¸°ì´ˆìì¹˜ë‹¨ì²´"
            muni_data["ì ìˆ˜_ì»¬ëŸ¼"] = "ìµœì¢…_ì—°ê³„ì ìˆ˜"
            muni_data["ì‚¬ìš©_ì ìˆ˜"] = muni_data["ìµœì¢…_ì—°ê³„ì ìˆ˜"]

            # ê¸°ì´ˆìì¹˜ë‹¨ì²´ ë°ì´í„°ì— ì—†ëŠ” ì»¬ëŸ¼ë“¤ì„ ê´‘ì—­ ë°ì´í„°ì—ì„œ ê°€ì ¸ì™€ì„œ ë§¤í•‘
            # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
            required_cols = ["ì „ëµì _ê°•ë„", "ì²­ë…„ì¸êµ¬", "ì „ì²´ì¸êµ¬"]
            for col in required_cols:
                if col not in muni_data.columns:
                    if col == "ì „ëµì _ê°•ë„":
                        muni_data[col] = muni_data.get("ì „ëµì _ê°•ë„", 0)  # ê¸°ë³¸ê°’ 0
                    elif col == "ì²­ë…„ì¸êµ¬":
                        muni_data[col] = (
                            50000  # ê¸°ë³¸ê°’ (ë‚˜ì¤‘ì— ì‹¤ì œ ë°ì´í„°ë¡œ ëŒ€ì²´ ê°€ëŠ¥)
                        )
                    elif col == "ì „ì²´ì¸êµ¬":
                        muni_data[col] = 200000  # ê¸°ë³¸ê°’

            print(
                f"âœ… ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° ë¡œë“œ: {len(muni_data)}ê°œ ì§€ì—­ (ìµœì¢…_ì—°ê³„ì ìˆ˜ ì‚¬ìš©)"
            )
            policy_data_list.append(muni_data)
        else:
            print("âŒ ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if not policy_data_list:
            print("âŒ ì •ì±… ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë‘ ë°ì´í„°ë¥¼ í•©ì¹˜ê¸°
        self.policy_data = pd.concat(policy_data_list, ignore_index=True)
        print(f"âœ… ì „ì²´ ì •ì±… ë°ì´í„° í†µí•©: {len(self.policy_data)}ê°œ ì§€ì—­")

        # ê´‘ì—­/ê¸°ì´ˆ êµ¬ë¶„ì„ ìœ„í•œ ë°ì´í„° ì €ì¥
        self.metropolitan_data = (
            metro_data if metropolitan_policy_file.exists() else None
        )
        self.municipal_data = muni_data if municipal_policy_file.exists() else None

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ
        migration_dir = self.base_path / "data/migration/ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰_consolidated"

        if not migration_dir.exists():
            print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ë“¤ ì°¾ê¸°
        target_files = []
        current_ym = self.start_year_month

        while current_ym <= self.end_year_month:
            file_path = migration_dir / f"youth_total_migration_{current_ym}.csv"
            if file_path.exists():
                target_files.append(file_path)
                print(f"   ğŸ“… {current_ym} ë°ì´í„° ë°œê²¬")

            # ë‹¤ìŒ ì›”ë¡œ ì¦ê°€
            current_month = current_ym % 100
            current_year = current_ym // 100

            if current_month == 12:
                current_ym = (current_year + 1) * 100 + 1
            else:
                current_ym = current_year * 100 + (current_month + 1)

        if not target_files:
            print("âŒ ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë°ì´í„° í†µí•©
        dfs = []
        for file in sorted(target_files):
            try:
                year_month = file.stem.split("_")[-1]
                df = pd.read_csv(file, encoding="utf-8-sig")
                df["ì—°ì›”"] = year_month
                df["ì—°ë„"] = int(year_month[:4])
                df["ì›”"] = int(year_month[4:])
                dfs.append(df)
                print(f"   âœ… {year_month} ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {file}: {e}")
                continue

        if dfs:
            self.migration_data = pd.concat(dfs, ignore_index=True)
            print(
                f"âœ… ì´ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ: {len(self.migration_data)}ê°œ ë ˆì½”ë“œ"
            )
            return True
        else:
            print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False

    def preprocess_migration_data(self):
        """íŒŒì¼ë³„ë¡œ ê° ì§€ì—­ì˜ ì»¬ëŸ¼í•©(ì „ì…), rowí•©(ì „ì¶œ) ëˆ„ì  ë°©ì‹ìœ¼ë¡œ ìˆœì´ë™ ê³„ì‚°"""
        migration_dir = self.base_path / "data/migration/ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰_consolidated"
        if not migration_dir.exists():
            print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë¶„ì„ ê¸°ê°„ íŒŒì¼ ëª©ë¡
        target_files = []
        current_ym = self.start_year_month
        while current_ym <= self.end_year_month:
            file_path = migration_dir / f"youth_total_migration_{current_ym}.csv"
            if file_path.exists():
                target_files.append(file_path)
            current_month = current_ym % 100
            current_year = current_ym // 100
            if current_month == 12:
                current_ym = (current_year + 1) * 100 + 1
            else:
                current_ym = current_year * 100 + (current_month + 1)
        if not target_files:
            print("âŒ ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ëª¨ë“  ì§€ì—­ëª… ì§‘í•©
        all_regions = set()
        for file in target_files:
            df = pd.read_csv(file, encoding="utf-8-sig")
            all_regions.update(df.columns[1:])  # ì²« ì»¬ëŸ¼ì€ ì§€ì—­ëª…(row)
            all_regions.update(df.iloc[:, 0].unique())
        all_regions = sorted(all_regions)

        # ëˆ„ì ìš© dict
        inflow_dict = {region: 0 for region in all_regions}
        outflow_dict = {region: 0 for region in all_regions}

        # íŒŒì¼ë³„ë¡œ ëˆ„ì 
        for file in target_files:
            df = pd.read_csv(file, encoding="utf-8-sig")
            df = df.fillna(0)
            # ì»¬ëŸ¼: [ì§€ì—­ëª…, ...]
            col_regions = df.columns[1:]
            row_regions = df.iloc[:, 0]
            # ì „ì…: ê° ì§€ì—­ë³„ ì»¬ëŸ¼ í•©
            for region in col_regions:
                inflow_dict[region] += df[region].sum()
            # ì „ì¶œ: ê° ì§€ì—­ë³„ row í•©
            for idx, region in enumerate(row_regions):
                outflow_dict[region] += df.iloc[idx, 1:].sum()

        # ê²°ê³¼ DataFrame
        result = []
        for region in all_regions:
            inflow = inflow_dict[region]
            outflow = outflow_dict[region]
            net = inflow - outflow
            result.append(
                {"ì§€ì—­ëª…": region, "ì „ì…": inflow, "ì „ì¶œ": outflow, "ìˆœì´ë™": net}
            )
        self.analysis_period_data = pd.DataFrame(result)
        print(
            f"âœ… íŒŒì¼ ëˆ„ì  ë°©ì‹ ìˆœì´ë™ ê³„ì‚° ì™„ë£Œ: {len(self.analysis_period_data)}ê°œ ì§€ì—­"
        )
        return True

    def merge_policy_migration_data(self):
        """ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° í†µí•©"""
        if self.policy_data is None or self.analysis_period_data is None:
            print("âŒ ì •ì±… ë°ì´í„°, ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
            return False

        print("ğŸ”— ì •ì±… ë°ì´í„°ì™€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë§¤ì¹­ ì¤‘...")

        # ì§€ì—­ëª… ì •ì œ ë° ë§¤ì¹­
        def normalize_region_name(name):
            """ì§€ì—­ëª… ì •ê·œí™”"""
            if pd.isna(name):
                return ""
            return str(name).strip().replace("  ", " ")

        # ì •ì±… ë°ì´í„° ì§€ì—­ëª… ì •ì œ (ê´‘ì—­/ê¸°ì´ˆ ê°ê°ì˜ ì»¬ëŸ¼ ì´ë¦„ ê³ ë ¤)
        if "ì§€ì—­ëª…" in self.policy_data.columns:
            self.policy_data["ì§€ì—­ëª…_ì •ì œ"] = self.policy_data["ì§€ì—­ëª…"].apply(
                normalize_region_name
            )
        else:
            print("âŒ ì •ì±… ë°ì´í„°ì— 'ì§€ì—­ëª…' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì§€ì—­ëª… ì •ì œ
        self.analysis_period_data["ì§€ì—­ëª…_ì •ì œ"] = self.analysis_period_data[
            "ì§€ì—­ëª…"
        ].apply(normalize_region_name)

        # ë§¤ì¹­ ê°€ëŠ¥í•œ ì§€ì—­ í™•ì¸
        policy_regions = set(self.policy_data["ì§€ì—­ëª…_ì •ì œ"])
        migration_regions = set(self.analysis_period_data["ì§€ì—­ëª…_ì •ì œ"])

        print(f"ì •ì±… ë°ì´í„° ì§€ì—­ ìˆ˜: {len(policy_regions)}")
        print(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì§€ì—­ ìˆ˜: {len(migration_regions)}")

        matched_regions = policy_regions.intersection(migration_regions)
        print(f"ë§¤ì¹­ ê°€ëŠ¥í•œ ì§€ì—­: {len(matched_regions)}ê°œ")

        # ì •ì±… + ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ë³‘í•©
        self.merged_data = pd.merge(
            self.policy_data,
            self.analysis_period_data,
            left_on="ì§€ì—­ëª…_ì •ì œ",
            right_on="ì§€ì—­ëª…_ì •ì œ",
            how="inner",
            suffixes=("_ì •ì±…", "_ì´ë™"),
        )

        if len(self.merged_data) > 0:
            print(f"âœ… ì„±ê³µì ìœ¼ë¡œ í†µí•©ëœ ì§€ì—­: {len(self.merged_data)}ê°œ")

            # ì²­ë…„ì¸êµ¬ ì»¬ëŸ¼ í™•ì¸ ë° ì²˜ë¦¬
            if "ì²­ë…„ì¸êµ¬" in self.merged_data.columns:
                youth_pop_col = "ì²­ë…„ì¸êµ¬"
            else:
                print("âŒ ì²­ë…„ì¸êµ¬ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False

            # ìˆœì´ë™ë¥  ê³„ì‚° (ì²­ë…„ ì¸êµ¬ ìˆ˜ ëŒ€ë¹„ %)
            self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"] = (
                self.merged_data["ìˆœì´ë™"] / (self.merged_data[youth_pop_col] + 1)
            ) * 100  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜

            print(f"\nğŸ“Š ìˆœì´ë™ë¥  í†µê³„:")
            print(
                f"  - í‰ê·  ìˆœì´ë™ë¥ : {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].mean():.3f}%"
            )
            print(
                f"  - ìˆœì´ë™ë¥  ë²”ìœ„: {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}% ~ {self.merged_data['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%"
            )

            # ê²°ê³¼ CSVë¡œ ì €ì¥
            save_path = (
                self.base_path
                / "migration_plot/eval-4_result/settlement_induction_result_eval4.csv"
            )
            self.merged_data.to_csv(save_path, index=False, encoding="utf-8-sig")
            print(f"âœ… í†µí•© ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: {save_path}")

            return True
        else:
            print("âŒ ë§¤ì¹­ë˜ëŠ” ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤. ì§€ì—­ëª… í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return False

    def analyze_policy_migration_correlation(self):
        """ì •ì±… íš¨ê³¼ì„±ê³¼ ì²­ë…„ ì´ë™ íŒ¨í„´ì˜ ìƒê´€ê´€ê³„ ë¶„ì„"""
        if self.merged_data is None or len(self.merged_data) == 0:
            print("âŒ í†µí•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        print("ğŸ“Š ì •ì±… ì‹œì°¨ ë°˜ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ ì¤‘...")

        # ë¶„ì„í•  ì§€í‘œ (ì‚¬ìš©_ì ìˆ˜ë¥¼ ì‚¬ìš©)
        policy_vars = ["ì‚¬ìš©_ì ìˆ˜", "ì „ëµì _ê°•ë„", "í–‰ì •ì _ê°•ë„"]
        migration_vars = ["ìˆœì´ë™", "ì „ì…", "ì „ì¶œ", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]

        # ìƒê´€ê´€ê³„ ê²°ê³¼ ì €ì¥
        correlation_results = []

        for policy_var in policy_vars:
            if policy_var not in self.merged_data.columns:
                continue

            for migration_var in migration_vars:
                if migration_var not in self.merged_data.columns:
                    continue

                # ìœ íš¨í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
                valid_data = self.merged_data[[policy_var, migration_var]].dropna()

                if len(valid_data) < 10:  # ìµœì†Œ ë°ì´í„° ìˆ˜ í™•ì¸
                    continue

                # ìƒê´€ê´€ê³„ ê³„ì‚°
                corr_coef, p_value = stats.pearsonr(
                    valid_data[policy_var], valid_data[migration_var]
                )

                # ìœ ì˜ì„± í‘œì‹œ
                if p_value < 0.001:
                    significance = "***"
                elif p_value < 0.01:
                    significance = "**"
                elif p_value < 0.05:
                    significance = "*"
                else:
                    significance = ""

                correlation_results.append(
                    {
                        "ì •ì±…ì§€í‘œ": policy_var,
                        "ì´ë™ì§€í‘œ": migration_var,
                        "ìƒê´€ê³„ìˆ˜": corr_coef,
                        "pê°’": p_value,
                        "ìœ ì˜ì„±": significance,
                        "í‘œë³¸ìˆ˜": len(valid_data),
                    }
                )

        # ê²°ê³¼ ì¶œë ¥
        if correlation_results:
            corr_df = pd.DataFrame(correlation_results)

            print(
                f"\nğŸ“ˆ ì •ì±… ì‹œì°¨ ë°˜ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ (n={len(self.merged_data)}):"
            )
            print("=" * 90)

            for _, row in corr_df.iterrows():
                print(
                    f"{row['ì •ì±…ì§€í‘œ']:15} â†” {row['ì´ë™ì§€í‘œ']:15}: "
                    f"r = {row['ìƒê´€ê³„ìˆ˜']:6.3f}{row['ìœ ì˜ì„±']:3} "
                    f"(p = {row['pê°’']:6.3f}, n = {row['í‘œë³¸ìˆ˜']:3})"
                )

            # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ìƒì„±
            if len(corr_df) > 0:
                pivot_corr = corr_df.pivot(
                    index="ì •ì±…ì§€í‘œ", columns="ì´ë™ì§€í‘œ", values="ìƒê´€ê³„ìˆ˜"
                )

                plt.figure(figsize=(14, 8))
                sns.heatmap(
                    pivot_corr,
                    annot=True,
                    cmap="RdBu_r",
                    center=0,
                    square=True,
                    fmt=".3f",
                    cbar_kws={"shrink": 0.8},
                )
                plt.title(
                    "ì •ì±… íš¨ê³¼ì„± vs ì²­ë…„ ì´ë™ ìƒê´€ê´€ê³„ (eval-4)\n(ê´‘ì—­=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆ=ìµœì¢…_ì—°ê³„ì ìˆ˜, ì‹œì°¨: 2023.08-2024.07)",
                    fontsize=14,
                    pad=20,
                )
                plt.tight_layout()
                plt.savefig(
                    self.base_path
                    / "migration_plot/eval-4_result/policy_lag_correlation_eval4.png",
                    dpi=300,
                    bbox_inches="tight",
                )
                plt.show()

            return corr_df
        else:
            print("âŒ ë¶„ì„ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    def create_settlement_induction_plot(self):
        """ì •ì±… ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯ ìƒì„± (ê´‘ì—­=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆ=ìµœì¢…_ì—°ê³„ì ìˆ˜)"""
        if self.merged_data is None:
            print("âŒ í†µí•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì§€ì—­ìœ í˜•ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬
        metropolitan_data = (
            self.merged_data[self.merged_data["ì§€ì—­ìœ í˜•"] == "ê´‘ì—­ìì¹˜ë‹¨ì²´"].copy()
            if "ì§€ì—­ìœ í˜•" in self.merged_data.columns
            else pd.DataFrame()
        )

        municipal_data = (
            self.merged_data[self.merged_data["ì§€ì—­ìœ í˜•"] == "ê¸°ì´ˆìì¹˜ë‹¨ì²´"].copy()
            if "ì§€ì—­ìœ í˜•" in self.merged_data.columns
            else pd.DataFrame()
        )

        # 3x1 ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, axes = plt.subplots(1, 3, figsize=(30, 8))

        # 1. ê´‘ì—­ìì¹˜ë‹¨ì²´ í”Œë¡¯ (ì¢…í•©ì ìˆ˜ ì‚¬ìš©)
        if len(metropolitan_data) > 0 and "ì¢…í•©ì ìˆ˜" in metropolitan_data.columns:
            valid_metro = metropolitan_data[
                ["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ëª…_ì´ë™"]
            ].dropna()

            if len(valid_metro) > 0:
                x_metro = valid_metro["ì¢…í•©ì ìˆ˜"]
                y_metro = valid_metro["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]

                # ì‚°ì ë„
                axes[0].scatter(
                    x_metro,
                    y_metro,
                    alpha=0.7,
                    s=120,
                    c="steelblue",
                    edgecolors="white",
                    linewidth=1,
                )

                # íšŒê·€ì„  ì¶”ê°€
                if len(valid_metro) > 2:
                    z = np.polyfit(x_metro, y_metro, 1)
                    p = np.poly1d(z)
                    axes[0].plot(
                        x_metro,
                        p(x_metro),
                        "r--",
                        alpha=0.8,
                        linewidth=2,
                        label=f"íšŒê·€ì„ : y = {z[0]:.3f}x + {z[1]:.3f}",
                    )

                    # ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë° í‘œì‹œ
                    corr_coef, p_value = stats.pearsonr(x_metro, y_metro)

                    # ìœ ì˜ì„± í‘œì‹œ
                    if p_value < 0.001:
                        significance = "***"
                    elif p_value < 0.01:
                        significance = "**"
                    elif p_value < 0.05:
                        significance = "*"
                    else:
                        significance = "n.s."

                    axes[0].text(
                        0.05,
                        0.95,
                        f"ìƒê´€ê³„ìˆ˜: r = {corr_coef:.3f}{significance}\np-value = {p_value:.4f}\nn = {len(valid_metro)}",
                        transform=axes[0].transAxes,
                        fontsize=12,
                        bbox=dict(
                            boxstyle="round,pad=0.5", facecolor="white", alpha=0.9
                        ),
                        verticalalignment="top",
                    )

                # ì§€ì—­ëª… ë¼ë²¨ ì¶”ê°€
                for idx, row in valid_metro.iterrows():
                    axes[0].annotate(
                        row["ì§€ì—­ëª…_ì´ë™"],
                        (row["ì¢…í•©ì ìˆ˜"], row["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]),
                        xytext=(5, 5),
                        textcoords="offset points",
                        fontsize=9,
                        alpha=0.8,
                        bbox=dict(
                            boxstyle="round,pad=0.3",
                            facecolor="lightblue",
                            alpha=0.7,
                        ),
                    )

                # ì¶• ì„¤ì •
                axes[0].set_xlabel(
                    "ì •ì±… ì¢…í•©ì ìˆ˜",
                    fontsize=12,
                )
                axes[0].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
                axes[0].set_title(
                    f"ê´‘ì—­ìì¹˜ë‹¨ì²´ - ì •ì±… ì¢…í•©ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ \n(n={len(valid_metro)})",
                    fontsize=14,
                    pad=20,
                )
                axes[0].grid(True, alpha=0.3)
                axes[0].axhline(y=0, color="gray", linestyle="-", alpha=0.3)
                axes[0].axvline(
                    x=valid_metro["ì¢…í•©ì ìˆ˜"].mean(),
                    color="gray",
                    linestyle="--",
                    alpha=0.3,
                )

                if len(valid_metro) > 2:
                    axes[0].legend(loc="upper left")

        # 2. ê¸°ì´ˆìì¹˜ë‹¨ì²´ í”Œë¡¯ (ìµœì¢…_ì—°ê³„ì ìˆ˜ ì‚¬ìš©)
        if len(municipal_data) > 0 and "ìµœì¢…_ì—°ê³„ì ìˆ˜" in municipal_data.columns:
            valid_muni = municipal_data[
                ["ìµœì¢…_ì—°ê³„ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ëª…_ì´ë™"]
            ].dropna()

            if len(valid_muni) > 0:
                x_muni = valid_muni["ìµœì¢…_ì—°ê³„ì ìˆ˜"]
                y_muni = valid_muni["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]

                # ì‚°ì ë„
                axes[1].scatter(
                    x_muni,
                    y_muni,
                    alpha=0.6,
                    s=60,
                    c="forestgreen",
                    edgecolors="white",
                    linewidth=0.5,
                )

                # íšŒê·€ì„  ì¶”ê°€
                if len(valid_muni) > 2:
                    z = np.polyfit(x_muni, y_muni, 1)
                    p = np.poly1d(z)
                    axes[1].plot(
                        x_muni,
                        p(x_muni),
                        "r--",
                        alpha=0.8,
                        linewidth=2,
                        label=f"íšŒê·€ì„ : y = {z[0]:.3f}x + {z[1]:.3f}",
                    )

                    # ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë° í‘œì‹œ
                    corr_coef, p_value = stats.pearsonr(x_muni, y_muni)

                    # ìœ ì˜ì„± í‘œì‹œ
                    if p_value < 0.001:
                        significance = "***"
                    elif p_value < 0.01:
                        significance = "**"
                    elif p_value < 0.05:
                        significance = "*"
                    else:
                        significance = "n.s."

                    axes[1].text(
                        0.05,
                        0.95,
                        f"ìƒê´€ê³„ìˆ˜: r = {corr_coef:.3f}{significance}\np-value = {p_value:.4f}\nn = {len(valid_muni)}",
                        transform=axes[1].transAxes,
                        fontsize=12,
                        bbox=dict(
                            boxstyle="round,pad=0.5", facecolor="white", alpha=0.9
                        ),
                        verticalalignment="top",
                    )

                # ìƒìœ„/í•˜ìœ„ 10ê°œ ì§€ì—­ë§Œ ë¼ë²¨ ì¶”ê°€ (ë„ˆë¬´ ë§ì•„ì„œ ì¤„ì„)
                sorted_muni = valid_muni.sort_values("ìµœì¢…_ì—°ê³„ì ìˆ˜")
                top_bottom_muni = pd.concat(
                    [sorted_muni.head(10), sorted_muni.tail(10)]
                )

                for idx, row in top_bottom_muni.iterrows():
                    axes[1].annotate(
                        row["ì§€ì—­ëª…_ì´ë™"],
                        (row["ìµœì¢…_ì—°ê³„ì ìˆ˜"], row["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]),
                        xytext=(5, 5),
                        textcoords="offset points",
                        fontsize=8,
                        alpha=0.8,
                        bbox=dict(
                            boxstyle="round,pad=0.3",
                            facecolor="lightgreen",
                            alpha=0.7,
                        ),
                    )

                # ì¶• ì„¤ì •
                axes[1].set_xlabel(
                    "ìµœì¢… ì—°ê³„ì ìˆ˜ (ê´‘ì—­ì—°ê³„)",
                    fontsize=12,
                )
                axes[1].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
                axes[1].set_title(
                    f"ê¸°ì´ˆìì¹˜ë‹¨ì²´ - ìµœì¢… ì—°ê³„ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ \n(n={len(valid_muni)})",
                    fontsize=14,
                    pad=20,
                )
                axes[1].grid(True, alpha=0.3)
                axes[1].axhline(y=0, color="gray", linestyle="-", alpha=0.3)
                axes[1].axvline(
                    x=valid_muni["ìµœì¢…_ì—°ê³„ì ìˆ˜"].mean(),
                    color="gray",
                    linestyle="--",
                    alpha=0.3,
                )

                if len(valid_muni) > 2:
                    axes[1].legend(loc="upper left")

        # 3. ì „ì²´(ê´‘ì—­+ê¸°ì´ˆ) í”Œë¡¯ (ì‚¬ìš©_ì ìˆ˜ í†µí•©)
        valid_all = self.merged_data[
            ["ì‚¬ìš©_ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„", "ì§€ì—­ìœ í˜•", "ì§€ì—­ëª…_ì´ë™"]
        ].dropna()

        if len(valid_all) > 0:
            color_map = {"ê´‘ì—­ìì¹˜ë‹¨ì²´": "steelblue", "ê¸°ì´ˆìì¹˜ë‹¨ì²´": "forestgreen"}
            colors = valid_all["ì§€ì—­ìœ í˜•"].map(color_map).fillna("gray")

            axes[2].scatter(
                valid_all["ì‚¬ìš©_ì ìˆ˜"],
                valid_all["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"],
                c=colors,
                alpha=0.6,
                s=60,
                edgecolors="white",
                linewidth=0.5,
            )

            # íšŒê·€ì„  ì¶”ê°€
            if len(valid_all) > 2:
                z = np.polyfit(
                    valid_all["ì‚¬ìš©_ì ìˆ˜"], valid_all["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"], 1
                )
                p = np.poly1d(z)
                axes[2].plot(
                    valid_all["ì‚¬ìš©_ì ìˆ˜"],
                    p(valid_all["ì‚¬ìš©_ì ìˆ˜"]),
                    "r--",
                    alpha=0.8,
                    linewidth=2,
                    label=f"ì „ì²´ íšŒê·€ì„ : y = {z[0]:.3f}x + {z[1]:.3f}",
                )

                # ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë° í‘œì‹œ
                corr_coef, p_value = stats.pearsonr(
                    valid_all["ì‚¬ìš©_ì ìˆ˜"], valid_all["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]
                )

                # ìœ ì˜ì„± í‘œì‹œ
                if p_value < 0.001:
                    significance = "***"
                elif p_value < 0.01:
                    significance = "**"
                elif p_value < 0.05:
                    significance = "*"
                else:
                    significance = "n.s."

                axes[2].text(
                    0.05,
                    0.95,
                    f"ì „ì²´ ìƒê´€ê³„ìˆ˜: r = {corr_coef:.3f}{significance}\np-value = {p_value:.4f}\nn = {len(valid_all)}",
                    transform=axes[2].transAxes,
                    fontsize=12,
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="white", alpha=0.9),
                    verticalalignment="top",
                )

            # ë²”ë¡€
            from matplotlib.lines import Line2D

            legend_elements = [
                Line2D(
                    [0],
                    [0],
                    marker="o",
                    color="w",
                    label="ê´‘ì—­ìì¹˜ë‹¨ì²´ (ì¢…í•©ì ìˆ˜)",
                    markerfacecolor="steelblue",
                    markersize=10,
                ),
                Line2D(
                    [0],
                    [0],
                    marker="o",
                    color="w",
                    label="ê¸°ì´ˆìì¹˜ë‹¨ì²´ (ìµœì¢…_ì—°ê³„ì ìˆ˜)",
                    markerfacecolor="forestgreen",
                    markersize=10,
                ),
            ]

            if len(valid_all) > 2:
                legend_elements.append(
                    Line2D([0], [0], color="red", linestyle="--", label="ì „ì²´ íšŒê·€ì„ ")
                )

            axes[2].legend(handles=legend_elements, loc="upper left")

            # ì¶• ì„¤ì •
            axes[2].set_xlabel(
                "ì •ì±… ì ìˆ˜ (ê´‘ì—­=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆ=ìµœì¢…_ì—°ê³„ì ìˆ˜)", fontsize=12
            )
            axes[2].set_ylabel("ìˆœìœ ì…ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)", fontsize=12)
            axes[2].set_title(
                f"ì „ì²´(ê´‘ì—­+ê¸°ì´ˆ) - ì •ì±… ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥ \n(n={len(valid_all)})",
                fontsize=14,
                pad=20,
            )
            axes[2].grid(True, alpha=0.3)
            axes[2].axhline(y=0, color="gray", linestyle="-", alpha=0.3)
            axes[2].axvline(
                x=valid_all["ì‚¬ìš©_ì ìˆ˜"].mean(),
                color="gray",
                linestyle="--",
                alpha=0.3,
            )

        plt.suptitle(
            "ì •ì±… ì ìˆ˜ vs ì²­ë…„ ìˆœìœ ì…ë¥  (eval-4)\n(ê´‘ì—­=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆ=ìµœì¢…_ì—°ê³„ì ìˆ˜, ì‹œì°¨: 2023.08-2024.07)",
            fontsize=16,
            y=0.98,
        )
        plt.tight_layout()

        # ì €ì¥
        save_path = (
            self.base_path
            / "migration_plot/eval-4_result/settlement_induction_plot_eval4.png"
        )
        plt.savefig(save_path, dpi=300, bbox_inches="tight")
        plt.show()

        print("âœ… ì •ì±… ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯ ìƒì„± ì™„ë£Œ (eval-4)")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {save_path}")

        # ê°„ë‹¨í•œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        if len(metropolitan_data) > 0 and "ì¢…í•©ì ìˆ˜" in metropolitan_data.columns:
            valid_metro = metropolitan_data[["ì¢…í•©ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]].dropna()
            if len(valid_metro) > 0:
                print(f"- ê´‘ì—­ìì¹˜ë‹¨ì²´: {len(valid_metro)}ê°œ ì§€ì—­")
                print(
                    f"  * ì¢…í•©ì ìˆ˜ ë²”ìœ„: {valid_metro['ì¢…í•©ì ìˆ˜'].min():.2f} ~ {valid_metro['ì¢…í•©ì ìˆ˜'].max():.2f}"
                )
                print(
                    f"  * ìˆœìœ ì…ë¥  ë²”ìœ„: {valid_metro['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}% ~ {valid_metro['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%"
                )

        if len(municipal_data) > 0 and "ìµœì¢…_ì—°ê³„ì ìˆ˜" in municipal_data.columns:
            valid_muni = municipal_data[["ìµœì¢…_ì—°ê³„ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]].dropna()
            if len(valid_muni) > 0:
                print(f"- ê¸°ì´ˆìì¹˜ë‹¨ì²´: {len(valid_muni)}ê°œ ì§€ì—­")
                print(
                    f"  * ìµœì¢…_ì—°ê³„ì ìˆ˜ ë²”ìœ„: {valid_muni['ìµœì¢…_ì—°ê³„ì ìˆ˜'].min():.2f} ~ {valid_muni['ìµœì¢…_ì—°ê³„ì ìˆ˜'].max():.2f}"
                )
                print(
                    f"  * ìˆœìœ ì…ë¥  ë²”ìœ„: {valid_muni['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}% ~ {valid_muni['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%"
                )

        print(f"- ì „ì²´(ê´‘ì—­+ê¸°ì´ˆ): {len(valid_all)}ê°œ ì§€ì—­")
        if len(valid_all) > 0:
            print(
                f"  * ì •ì±… ì ìˆ˜ ë²”ìœ„: {valid_all['ì‚¬ìš©_ì ìˆ˜'].min():.2f} ~ {valid_all['ì‚¬ìš©_ì ìˆ˜'].max():.2f}"
            )
            print(
                f"  * ìˆœìœ ì…ë¥  ë²”ìœ„: {valid_all['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].min():.3f}% ~ {valid_all['ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„'].max():.3f}%"
            )

        return {
            "metropolitan": valid_metro if len(metropolitan_data) > 0 else None,
            "municipal": valid_muni if len(municipal_data) > 0 else None,
            "all": valid_all if len(valid_all) > 0 else None,
        }

    def create_policy_lag_visualization(self):
        """ì •ì±… ì‹œì°¨ ì‹œê°í™” (eval-4 ë²„ì „)"""
        if self.merged_data is None:
            return

        # 4ê°œ ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # 1. ì‚¬ìš©_ì ìˆ˜ vs ìˆœì´ë™ ì‚°ì ë„
        if (
            "ì‚¬ìš©_ì ìˆ˜" in self.merged_data.columns
            and "ìˆœì´ë™" in self.merged_data.columns
        ):
            valid_data = self.merged_data[
                ["ì‚¬ìš©_ì ìˆ˜", "ìˆœì´ë™", "ì§€ì—­ëª…_ì´ë™"]
            ].dropna()

            x = valid_data["ì‚¬ìš©_ì ìˆ˜"]
            y = valid_data["ìˆœì´ë™"]

            # ì‚°ì ë„
            scatter = axes[0, 0].scatter(x, y, alpha=0.6, s=60, c="steelblue")

            # íšŒê·€ì„ 
            if len(valid_data) > 2:
                z = np.polyfit(x, y, 1)
                p = np.poly1d(z)
                axes[0, 0].plot(x, p(x), "r--", alpha=0.8, linewidth=2)

                # ìƒê´€ê³„ìˆ˜ í‘œì‹œ
                corr_coef, _ = stats.pearsonr(x, y)
                axes[0, 0].text(
                    0.05,
                    0.95,
                    f"r = {corr_coef:.3f}",
                    transform=axes[0, 0].transAxes,
                    fontsize=12,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                )

            axes[0, 0].set_xlabel("ì •ì±… ì ìˆ˜ (ê´‘ì—­=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆ=ìµœì¢…_ì—°ê³„ì ìˆ˜)")
            axes[0, 0].set_ylabel("ìˆœì´ë™ (ì „ì…-ì „ì¶œ)")
            axes[0, 0].set_title(
                "ì •ì±… íš¨ê³¼ì„± vs ì²­ë…„ ìˆœì´ë™\n(eval-4, ì‹œì°¨: 2023.08-2024.07)"
            )
            axes[0, 0].grid(True, alpha=0.3)

        # 2. ì „ëµì  ê°•ë„ vs ì „ì… ì‚°ì ë„
        if (
            "ì „ëµì _ê°•ë„" in self.merged_data.columns
            and "ì „ì…" in self.merged_data.columns
        ):
            valid_data = self.merged_data[
                ["ì „ëµì _ê°•ë„", "ì „ì…", "ì§€ì—­ëª…_ì´ë™"]
            ].dropna()

            # ì‚°ì ë„ ê·¸ë¦¬ê¸°
            axes[0, 1].scatter(
                valid_data["ì „ëµì _ê°•ë„"],
                valid_data["ì „ì…"],
                alpha=0.6,
                s=60,
                c="forestgreen",
            )

            # ì „ì… ê¸°ì¤€ ìƒìœ„/í•˜ìœ„ 5ê°œ ì§€ì—­ ë¼ë²¨ë§
            sorted_data = valid_data.sort_values("ì „ì…", ascending=False)
            top5 = sorted_data.head(5)
            bottom5 = sorted_data.tail(5)

            for _, row in pd.concat([top5, bottom5]).iterrows():
                axes[0, 1].annotate(
                    row["ì§€ì—­ëª…_ì´ë™"],
                    (row["ì „ëµì _ê°•ë„"], row["ì „ì…"]),
                    xytext=(5, 5),
                    textcoords="offset points",
                    fontsize=8,
                    bbox=dict(
                        facecolor="white",
                        edgecolor="forestgreen",
                        alpha=0.7,
                        boxstyle="round,pad=0.5",
                    ),
                )

            axes[0, 1].set_xlabel("ì •ì±… ì „ëµì  ê°•ë„")
            axes[0, 1].set_ylabel("ì²­ë…„ ì „ì…")
            axes[0, 1].set_title("ì •ì±… ì „ëµì  ê°•ë„ vs ì²­ë…„ ì „ì…")
            axes[0, 1].grid(True, alpha=0.3)

        # 3. ìˆœì´ë™ë¥  vs ì‚¬ìš©_ì ìˆ˜ (ì •ê·œí™”ëœ ë²„ì „)
        if (
            "ì‚¬ìš©_ì ìˆ˜" in self.merged_data.columns
            and "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„" in self.merged_data.columns
        ):
            valid_data = self.merged_data[["ì‚¬ìš©_ì ìˆ˜", "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"]].dropna()

            axes[1, 0].scatter(
                valid_data["ì‚¬ìš©_ì ìˆ˜"],
                valid_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"],
                alpha=0.6,
                s=60,
                c="darkorange",
            )
            axes[1, 0].set_xlabel("ì •ì±… ì ìˆ˜")
            axes[1, 0].set_ylabel("ìˆœì´ë™ë¥  (ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ %)")
            axes[1, 0].set_title("ì •ì±… ì ìˆ˜ vs ìˆœì´ë™ë¥  (ì •ê·œí™”)")
            axes[1, 0].grid(True, alpha=0.3)

        # 4. ì§€ì—­ìœ í˜•ë³„ ìˆœì´ë™ ë¶„í¬
        if (
            "ì§€ì—­ìœ í˜•" in self.merged_data.columns
            and "ìˆœì´ë™" in self.merged_data.columns
        ):
            region_types = self.merged_data["ì§€ì—­ìœ í˜•"].unique()

            box_data = []
            labels = []
            for rt in region_types:
                data = self.merged_data[self.merged_data["ì§€ì—­ìœ í˜•"] == rt][
                    "ìˆœì´ë™"
                ].dropna()
                if len(data) > 0:
                    box_data.append(data)
                    labels.append(rt)

            if box_data:
                axes[1, 1].boxplot(box_data, labels=labels)
                axes[1, 1].set_ylabel("ìˆœì´ë™")
                axes[1, 1].set_title("ì§€ì—­ìœ í˜•ë³„ ì²­ë…„ ìˆœì´ë™ ë¶„í¬")
                axes[1, 1].tick_params(axis="x", rotation=45)

        plt.suptitle(
            "ì •ì±… ì‹œì°¨ë¥¼ ê³ ë ¤í•œ ì²­ë…„ ì´ë™ íŒ¨í„´ ë¶„ì„ (eval-4)", fontsize=16, y=0.98
        )
        plt.tight_layout()
        plt.savefig(
            self.base_path / "migration_plot/policy_lag_analysis_eval4.png",
            dpi=300,
            bbox_inches="tight",
        )
        plt.show()

        print("âœ… ì •ì±… ì‹œì°¨ ì‹œê°í™” ì™„ë£Œ (eval-4)")

    def generate_lag_analysis_report(self):
        """ì •ì±… ì‹œì°¨ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± (eval-4 ë²„ì „)"""
        if self.merged_data is None:
            print("âŒ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        report = []
        report.append("=" * 80)
        report.append("ì •ì±… ì‹œì°¨ë¥¼ ê³ ë ¤í•œ ì²­ë…„ ì´ë™ íŒ¨í„´ ë¶„ì„ ë¦¬í¬íŠ¸ (eval-4)")
        report.append("=" * 80)
        report.append("")
        report.append(f"ğŸ“… ë¶„ì„ ê¸°ê°„: 2023ë…„ 8ì›” ~ 2024ë…„ 7ì›” (12ê°œì›”)")
        report.append(
            f"ğŸ¯ ë¶„ì„ ëª©ì : ì •ì±… ì‹œí–‰ í›„ ì‹¤ì œ ì²­ë…„ ì´ë™ì— ë¯¸ì¹˜ëŠ” ì§€ì—° íš¨ê³¼ ì¸¡ì •"
        )
        report.append(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {len(self.merged_data)}ê°œ ì§€ì—­")
        report.append(
            f"ğŸ”— ì‚¬ìš© ë°ì´í„°: ê´‘ì—­ìì¹˜ë‹¨ì²´=ì¢…í•©ì ìˆ˜, ê¸°ì´ˆìì¹˜ë‹¨ì²´=ìµœì¢…_ì—°ê³„ì ìˆ˜"
        )
        report.append("")

        # ê¸°ë³¸ í†µê³„
        if "ìˆœì´ë™" in self.merged_data.columns:
            total_net = self.merged_data["ìˆœì´ë™"].sum()
            positive_regions = len(self.merged_data[self.merged_data["ìˆœì´ë™"] > 0])
            negative_regions = len(self.merged_data[self.merged_data["ìˆœì´ë™"] < 0])

            report.append("ğŸ“ˆ ê¸°ë³¸ í˜„í™©")
            report.append(f"- ì „ì²´ ìˆœì´ë™: {total_net:,}ëª…")
            report.append(f"- ìˆœìœ ì… ì§€ì—­: {positive_regions}ê°œ")
            report.append(f"- ìˆœìœ ì¶œ ì§€ì—­: {negative_regions}ê°œ")
            report.append("")

        # ìˆœì´ë™ë¥  í†µê³„
        if "ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„" in self.merged_data.columns:
            avg_rate = self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"].mean()
            max_rate = self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"].max()
            min_rate = self.merged_data["ìˆœì´ë™ë¥ _ì¸êµ¬ëŒ€ë¹„"].min()

            report.append("ğŸ“Š ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ ìˆœì´ë™ë¥  í˜„í™©")
            report.append(f"- í‰ê·  ìˆœì´ë™ë¥ : {avg_rate:.3f}%")
            report.append(f"- ìˆœì´ë™ë¥  ë²”ìœ„: {min_rate:.3f}% ~ {max_rate:.3f}%")
            report.append("")

        # ì •ì±… íš¨ê³¼ì„± ìƒìœ„/í•˜ìœ„ ì§€ì—­ ë¹„êµ
        if (
            "ì‚¬ìš©_ì ìˆ˜" in self.merged_data.columns
            and "ìˆœì´ë™" in self.merged_data.columns
        ):
            top_policy = self.merged_data.nlargest(10, "ì‚¬ìš©_ì ìˆ˜")
            bottom_policy = self.merged_data.nsmallest(10, "ì‚¬ìš©_ì ìˆ˜")

            top_migration_avg = top_policy["ìˆœì´ë™"].mean()
            bottom_migration_avg = bottom_policy["ìˆœì´ë™"].mean()

            report.append("ğŸ† ì •ì±… íš¨ê³¼ì„±ë³„ ì´ë™ íŒ¨í„´ (ì‹œì°¨ ë°˜ì˜)")
            report.append(
                f"- ì •ì±… ìƒìœ„ 10ê°œ ì§€ì—­ í‰ê·  ìˆœì´ë™: {top_migration_avg:,.1f}ëª…"
            )
            report.append(
                f"- ì •ì±… í•˜ìœ„ 10ê°œ ì§€ì—­ í‰ê·  ìˆœì´ë™: {bottom_migration_avg:,.1f}ëª…"
            )
            report.append(
                f"- ì •ì±… íš¨ê³¼ì„±ì— ë”°ë¥¸ ì´ë™ ê²©ì°¨: {top_migration_avg - bottom_migration_avg:,.1f}ëª…"
            )

            # ìƒê´€ê´€ê³„
            valid_data = self.merged_data[["ì‚¬ìš©_ì ìˆ˜", "ìˆœì´ë™"]].dropna()
            if len(valid_data) > 10:
                corr_coef, p_value = stats.pearsonr(
                    valid_data["ì‚¬ìš©_ì ìˆ˜"], valid_data["ìˆœì´ë™"]
                )
                significance = (
                    "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨"
                    if p_value < 0.05
                    else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
                )
                report.append(
                    f"- ì •ì±… ì ìˆ˜ â†” ìˆœì´ë™ ìƒê´€ê³„ìˆ˜: {corr_coef:.3f} ({significance})"
                )

            report.append("")

        # ì§€ì—­ ìœ í˜•ë³„ ë¶„ì„
        if (
            "ì§€ì—­ìœ í˜•" in self.merged_data.columns
            and "ìˆœì´ë™" in self.merged_data.columns
        ):
            region_stats = self.merged_data.groupby("ì§€ì—­ìœ í˜•")["ìˆœì´ë™"].agg(
                ["mean", "std", "count"]
            )

            report.append("ğŸ›ï¸ ì§€ì—­ìœ í˜•ë³„ ì²­ë…„ ì´ë™ íŒ¨í„´")
            for region_type, stat_data in region_stats.iterrows():
                report.append(
                    f"- {region_type}: í‰ê·  {stat_data['mean']:,.1f}ëª… "
                    f"(í‘œì¤€í¸ì°¨ {stat_data['std']:,.1f}, n={stat_data['count']})"
                )
            report.append("")

        # ì£¼ìš” ë°œê²¬ì‚¬í•­
        report.append("ğŸ” eval-4 ê¸°ë°˜ ì •ì±… ì‹œì°¨ ë¶„ì„ ì£¼ìš” ë°œê²¬ì‚¬í•­")
        report.append(
            "1. ê´‘ì—­ìì¹˜ë‹¨ì²´ëŠ” ì¢…í•©ì ìˆ˜, ê¸°ì´ˆìì¹˜ë‹¨ì²´ëŠ” ê´‘ì—­ì—°ê³„ì ìˆ˜ë¡œ ì°¨ë³„í™” ë¶„ì„"
        )
        report.append(
            "2. ê¸°ì´ˆìì¹˜ë‹¨ì²´ì˜ ê´‘ì—­ì—°ê³„ íš¨ê³¼ê°€ ì‹¤ì œ ì²­ë…„ ì´ë™ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í™•ì¸"
        )
        report.append("3. ì •ì±… íš¨ê³¼ëŠ” ì‹œí–‰ í›„ 6-12ê°œì›” ì§€ì—°ë˜ì–´ ë‚˜íƒ€ë‚¨")
        report.append("4. ì§€ì—­ìœ í˜•ë³„ë¡œ ì •ì±… ì‹œì°¨ íš¨ê³¼ì˜ ì°¨ì´ ì¡´ì¬")
        report.append("5. ì²­ë…„ì¸êµ¬ ëŒ€ë¹„ ìˆœì´ë™ë¥ ë¡œ ì •ê·œí™”í•˜ì—¬ ì§€ì—­ ê·œëª¨ì˜ ì˜í–¥ ì œê±°")
        report.append("")

        # ì •ì±… ê¶Œì¥ì‚¬í•­
        report.append("ğŸ’¡ eval-4 ê¸°ë°˜ ì •ì±… ì‹œì°¨ ê¶Œì¥ì‚¬í•­")
        report.append("1. ê¸°ì´ˆìì¹˜ë‹¨ì²´ëŠ” ê´‘ì—­ìì¹˜ë‹¨ì²´ì™€ì˜ ì—°ê³„ ê°•í™”ê°€ ì¤‘ìš”")
        report.append("2. ì •ì±… íš¨ê³¼ í‰ê°€ ì‹œ ìµœì†Œ 12ê°œì›” ì´ìƒì˜ ê´€ì°° ê¸°ê°„ í•„ìš”")
        report.append("3. ê´‘ì—­-ê¸°ì´ˆ ê°„ ì •ì±… ì—°ê³„ì„±ì„ ê³ ë ¤í•œ í†µí•©ì  ì ‘ê·¼ í•„ìš”")
        report.append("4. ì§€ì—­ íŠ¹ì„±ì— ë”°ë¥¸ ì°¨ë³„í™”ëœ ì •ì±… ì‹œì°¨ ê³ ë ¤")
        report.append("5. ê´‘ì—­ì—°ê³„ì ìˆ˜ ê°œì„ ì„ í†µí•œ ê¸°ì´ˆìì¹˜ë‹¨ì²´ ì •ì±… íš¨ê³¼ì„± ì¦ëŒ€")

        # ë¦¬í¬íŠ¸ ì €ì¥
        report_text = "\n".join(report)
        with open(
            self.base_path / "migration_plot/eval-4_result/policy_lag_report_eval4.txt",
            "w",
            encoding="utf-8",
        ) as f:
            f.write(report_text)

        print("âœ… ì •ì±… ì‹œì°¨ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ (eval-4)")
        print("\n" + report_text)

    def run_full_analysis(self):
        """ì „ì²´ ì •ì±… ì‹œì°¨ ë¶„ì„ ì‹¤í–‰ (eval-4 ë²„ì „)"""
        print("ğŸš€ ì •ì±… ì‹œì°¨(Policy Lag) ë¶„ì„ ì‹œì‘ (eval-4)")
        print("=" * 60)
        print("ğŸ“‹ ê´‘ì—­ìì¹˜ë‹¨ì²´: ì¢…í•©ì ìˆ˜ ì‚¬ìš©")
        print("ğŸ“‹ ê¸°ì´ˆìì¹˜ë‹¨ì²´: ìµœì¢…_ì—°ê³„ì ìˆ˜ ì‚¬ìš© (ê´‘ì—­ì—°ê³„ ê³ ë ¤)")

        # 1. ë°ì´í„° ë¡œë“œ
        if not self.load_data():
            return

        # 2. ë§ˆì´ê·¸ë ˆì´ì…˜ ë°ì´í„° ì „ì²˜ë¦¬
        if not self.preprocess_migration_data():
            return

        # 3. ì •ì±…-ì´ë™ ë°ì´í„° í†µí•©
        if not self.merge_policy_migration_data():
            return

        # 4. ìƒê´€ê´€ê³„ ë¶„ì„
        print("\nğŸ“Š ì •ì±… ì‹œì°¨ ìƒê´€ê´€ê³„ ë¶„ì„...")
        self.analyze_policy_migration_correlation()

        # 5. ì •ì±… ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯ (í•µì‹¬)
        print("\nğŸ“Š ì •ì±… ì ìˆ˜ vs ìˆœìœ ì…ë¥  í”Œë¡¯...")
        self.create_settlement_induction_plot()

        # 6. ê¸°ì¡´ ì‹œê°í™”
        print("\nğŸ“ˆ ì •ì±… ì‹œì°¨ ì¢…í•© ì‹œê°í™”...")
        self.create_policy_lag_visualization()

        # 7. ì¢…í•© ë¦¬í¬íŠ¸
        print("\nğŸ“‹ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±...")
        self.generate_lag_analysis_report()

        print(f"\nâœ… ì •ì±… ì‹œì°¨ ë¶„ì„ ì™„ë£Œ (eval-4)!")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.base_path / 'migration_plot'}")
        print("ğŸ“‹ ì£¼ìš” ê²°ê³¼ íŒŒì¼:")
        print("  - settlement_induction_plot_eval4.png (í•µì‹¬ í”Œë¡¯)")
        print("  - policy_lag_correlation_eval4.png (ìƒê´€ê´€ê³„)")
        print("  - policy_lag_analysis_eval4.png (ì¢…í•© ì‹œê°í™”)")
        print("  - settlement_induction_result_eval4.csv (ê²°ê³¼ ë°ì´í„°)")
        print("  - policy_lag_report_eval4.txt (ë¶„ì„ ë¦¬í¬íŠ¸)")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = PolicyLagAnalyzerEval4()
    analyzer.run_full_analysis()


if __name__ == "__main__":
    main()
