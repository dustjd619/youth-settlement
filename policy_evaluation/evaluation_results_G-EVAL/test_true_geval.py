#!/usr/bin/env python3
"""
G-EVAL Form-filling Paradigm í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

G-EVAL ìˆ˜ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ:
score = Î£ p(si) * si
- í‰ê°€ ê¸°ì¤€ ì„¤ëª… + Chain-of-Thought + ì…ë ¥ ë¬¸ë§¥ + ì¶œë ¥ ê²°ê³¼(ë‹¨ë‹µ)
- 1-10ì  ë²”ìœ„ì—ì„œ log probability ê¸°ë°˜ ê°€ì¤‘í‰ê·  ê³„ì‚°
"""

import json
import os
import time
from datetime import datetime

from dotenv import load_dotenv
from policy_evaluation_system import (
    GEvalPolicyEvaluator,
    PolicyData,
    PolicyEvaluationSystem,
)


def save_single_test_results(policy, results, detailed_analyses, overall_score):
    """ë‹¨ì¼ ì •ì±… í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""

    # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"single_geval_test_{timestamp}.json"

    # ì €ì¥í•  ë°ì´í„° êµ¬ì¡°
    save_data = {
        "test_metadata": {
            "test_type": "Single Policy G-EVAL Test",
            "test_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "evaluation_method": "G-EVAL Form-filling Paradigm",
            "scoring_formula": "score = Î£ p(si) * si",
            "model_used": "gpt-4o-mini",
        },
        "policy_info": {
            "ì •ì±…ëª…": policy.name,
            "ì •ì±…ë‚´ìš©": policy.description,
            "ì˜ˆì‚°": f"{policy.budget}ë°±ë§Œì›" if policy.budget else "N/A",
            "ì¹´í…Œê³ ë¦¬": policy.category,
            "ì§€ì—­": policy.region,
            "ì—°ë„": policy.year,
            "ëŒ€ìƒê·¸ë£¹": policy.target_group,
        },
        "evaluation_results": {
            "ì ìˆ˜": {
                criterion: round(score, 2) for criterion, score in results.items()
            },
            "ì¢…í•©ì ìˆ˜": overall_score,
            "ìƒì„¸ë¶„ì„": detailed_analyses,
        },
        "summary": {
            "ìµœê³ ì ìˆ˜": f"{max(results.keys(), key=results.get)} ({max(results.values()):.2f}ì )",
            "ìµœì €ì ìˆ˜": f"{min(results.keys(), key=results.get)} ({min(results.values()):.2f}ì )",
            "ì ìˆ˜ë²”ìœ„": f"{min(results.values()):.2f} ~ {max(results.values()):.2f}",
            "í‘œì¤€í¸ì°¨": round(
                (sum((x - overall_score) ** 2 for x in results.values()) / len(results))
                ** 0.5,
                2,
            ),
        },
    }

    # íŒŒì¼ ì €ì¥
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
        print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {os.path.getsize(filename)} bytes")

    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")


def test_single_policy():
    """ë‹¨ì¼ ì •ì±…ìœ¼ë¡œ G-EVAL í…ŒìŠ¤íŠ¸"""

    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # í…ŒìŠ¤íŠ¸ìš© ì •ì±… ë°ì´í„°
    test_policy = PolicyData(
        name="ì²­ë…„ ì°½ì—… ì§€ì› í”„ë¡œê·¸ë¨",
        description="ë§Œ 18~39ì„¸ ì²­ë…„ì„ ëŒ€ìƒìœ¼ë¡œ ì°½ì—… ì•„ì´ë””ì–´ ê°œë°œë¶€í„° ì‚¬ì—…í™”ê¹Œì§€ ë‹¨ê³„ë³„ ë§ì¶¤í˜• ì§€ì›ì„ ì œê³µí•˜ëŠ” í”„ë¡œê·¸ë¨. ì°½ì—…êµìœ¡, ë©˜í† ë§, ìê¸ˆì§€ì›, ê³µê°„ì œê³µ ë“±ì„ í†µí•´ ì²­ë…„ ì°½ì—… ìƒíƒœê³„ë¥¼ ì¡°ì„±í•œë‹¤.",
        budget=150.0,
        category="ì°½ì—…ì§€ì›",
        region="ê²½ê¸°ë„",
        year=2024,
        target_group="ì²­ë…„",
    )

    print("ğŸ§ª G-EVAL Form-filling Paradigm í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"í…ŒìŠ¤íŠ¸ ì •ì±…: {test_policy.name}")
    print(f"ì„¤ëª…: {test_policy.description[:50]}...")
    print(f"ì˜ˆì‚°: {test_policy.budget}ë°±ë§Œì›")
    print("=" * 60)

    # G-EVAL í‰ê°€ì ì´ˆê¸°í™”
    evaluator = GEvalPolicyEvaluator(api_key, model="gpt-4o-mini")

    # ê° ê¸°ì¤€ë³„ë¡œ ê°œë³„ í…ŒìŠ¤íŠ¸
    criteria = ["íš¨ê³¼ì„±", "ì‹¤í˜„ê°€ëŠ¥ì„±", "í˜ì‹ ì„±", "ì§€ì†ê°€ëŠ¥ì„±", "ì˜ˆì‚°íš¨ìœ¨ì„±"]
    results = {}
    detailed_analyses = {}

    for i, criterion in enumerate(criteria, 1):
        print(f"\nğŸ“Š [{i}/{len(criteria)}] {criterion} í‰ê°€ ì¤‘...")

        try:
            score, analysis = evaluator._evaluate_criterion_with_geval(
                test_policy, criterion, f"{criterion} ê¸°ì¤€ìœ¼ë¡œ í‰ê°€"
            )

            results[criterion] = score
            detailed_analyses[criterion] = analysis

            print(f"âœ… {criterion} ì ìˆ˜: {score:.2f}ì ")

            # í™•ë¥  ë¶„í¬ ì •ë³´ê°€ ìˆë‹¤ë©´ ì¶œë ¥
            if "ã€G-EVAL í™•ë¥  ë¶„í¬ã€‘" in analysis:
                prob_section = analysis.split("ã€G-EVAL í™•ë¥  ë¶„í¬ã€‘")[1].split("\n")[1]
                print(f"ğŸ“ˆ í™•ë¥  ë¶„í¬: {prob_section}")

            print("-" * 40)

        except Exception as e:
            print(f"âŒ {criterion} í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
            results[criterion] = 5.0
            detailed_analyses[criterion] = (
                f"{criterion} í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            )

        # API í˜¸ì¶œ ì œí•œ
        if i < len(criteria):
            time.sleep(2)

    # ì¢…í•©ì ìˆ˜ ê³„ì‚°
    overall_score = round(sum(results.values()) / len(results), 2)

    print("\nğŸ¯ G-EVAL Form-filling Paradigm í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ“Š ì¢…í•©ì ìˆ˜: {overall_score}ì ")
    print("\nğŸ“‹ íŠ¹ì§•:")
    print("â€¢ Form-filling: í‰ê°€ ê¸°ì¤€ ì„¤ëª… + CoT + ë‹¨ë‹µí˜• ì ìˆ˜")
    print("â€¢ ìˆ˜ì‹: score = Î£ p(si) * si")
    print("â€¢ ë²”ìœ„: 1-10ì  log probability ê°€ì¤‘í‰ê· ")
    print("â€¢ ì¥ì : LLM ë¶ˆí™•ì‹¤ì„± ë°˜ì˜, ì—°ì†ì  ì ìˆ˜ ë¶„í¬")

    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    save_single_test_results(test_policy, results, detailed_analyses, overall_score)


def test_full_evaluation():
    """ì „ì²´ í‰ê°€ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸ (ì†Œìˆ˜ ì •ì±…)"""

    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    print("\nğŸš€ ì „ì²´ G-EVAL ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = PolicyEvaluationSystem(api_key, model="gpt-4o-mini")

    # ì „ì²´ G-EVAL í‰ê°€ ì‹¤í–‰ (ì „ì²´ ëª¨ë“œ)
    try:
        system.run_full_evaluation(
            gyeonggi_file="result_gyeonggi_policy.json",
            test_mode=False,  # ì „ì²´ ì •ì±… í‰ê°€
            evaluation_method="geval",
        )

        print("âœ… ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

        # ìƒì„±ëœ íŒŒì¼ í™•ì¸
        import glob

        geval_files = glob.glob("*geval*.json")
        if geval_files:
            print(f"\nğŸ’¾ ìƒì„±ëœ G-EVAL ê²°ê³¼ íŒŒì¼:")
            for file in sorted(geval_files)[-3:]:  # ìµœê·¼ 3ê°œ íŒŒì¼ë§Œ
                print(f"   ğŸ“„ {file} ({os.path.getsize(file)} bytes)")

    except Exception as e:
        print(f"âŒ ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    print("G-EVAL Form-filling Paradigm í…ŒìŠ¤íŠ¸")
    print("ì´ë¯¸ì§€ ê¸°ë°˜ ì§„ì •í•œ G-EVAL êµ¬í˜„")
    print("=" * 60)
    print("ğŸ’¾ ëª¨ë“  í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” ìë™ìœ¼ë¡œ JSON íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.")
    print("=" * 60)

    choice = input(
        "í…ŒìŠ¤íŠ¸ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:\n1. ë‹¨ì¼ ì •ì±… ìƒì„¸ í…ŒìŠ¤íŠ¸ (ê²°ê³¼ íŒŒì¼: single_geval_test_*.json)\n2. ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ê²°ê³¼ íŒŒì¼: test_gyeonggi_evaluation_geval_*.json)\nì„ íƒ (1 ë˜ëŠ” 2): "
    ).strip()

    if choice == "1":
        test_single_policy()
    elif choice == "2":
        test_full_evaluation()
    else:
        print("1 ë˜ëŠ” 2ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

    print("\nğŸ¯ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ğŸ“‹ ê²°ê³¼ íŒŒì¼ì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë©ë‹ˆë‹¤:")
    print("   â€¢ í…ŒìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° (ë‚ ì§œ, ëª¨ë¸, í‰ê°€ë°©ë²•)")
    print("   â€¢ ì •ì±… ì •ë³´ (ì´ë¦„, ë‚´ìš©, ì˜ˆì‚° ë“±)")
    print("   â€¢ í‰ê°€ ê²°ê³¼ (ê° ê¸°ì¤€ë³„ ì ìˆ˜, ì¢…í•©ì ìˆ˜)")
    print("   â€¢ ìƒì„¸ ë¶„ì„ (CoT ê³¼ì •, í™•ë¥  ë¶„í¬)")
    print("   â€¢ í†µê³„ ìš”ì•½ (ìµœê³ /ìµœì € ì ìˆ˜, í‘œì¤€í¸ì°¨ ë“±)")
