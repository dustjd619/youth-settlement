"""
ì§€ì—­ëª… í†µí•© ë° í‘œì¤€í™” ëª¨ë“ˆ
=========================

ì´ ëª¨ë“ˆì€ êµ¬ë¡œ ë‚˜ë‰˜ì–´ì§„ ì‹œ ë‹¨ìœ„ ì§€ì—­ë“¤ì„ í•˜ë‚˜ë¡œ í†µí•©í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ì˜ˆ: ê²½ê¸°ë„ ìš©ì¸ì‹œ ê¸°í¥êµ¬, ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬, ê²½ê¸°ë„ ìš©ì¸ì‹œ ì²˜ì¸êµ¬ â†’ ê²½ê¸°ë„ ìš©ì¸ì‹œ

ì‚¬ìš©ì ìš”ì²­ í†µí•© ëŒ€ìƒ:
- ê²½ê¸°ë„ ê³ ì–‘ì‹œ, ì„±ë‚¨ì‹œ, ìˆ˜ì›ì‹œ, ì•ˆì‚°ì‹œ, ì•ˆì–‘ì‹œ, ìš©ì¸ì‹œ
- ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ
- ê²½ìƒë¶ë„ í¬í•­ì‹œ
- ì „ë¼ë¶ë„ ì „ì£¼ì‹œ
- ì œì£¼íŠ¹ë³„ìì¹˜ë„
- ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œ
- ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œ
"""

import re
import shutil
from pathlib import Path

import numpy as np
import pandas as pd


class RegionConsolidator:
    """ì§€ì—­ëª… í†µí•© ë° í‘œì¤€í™” í´ë˜ìŠ¤"""

    def __init__(self):
        # ì‹œë„ëª… í‘œì¤€í™” ê·œì¹™ (íŠ¹ë³„ìì¹˜ë„ â†’ ì¼ë°˜ ëª…ì¹­)
        self.province_standardization = {
            "ê°•ì›íŠ¹ë³„ìì¹˜ë„": "ê°•ì›ë„",
            "ì „ë¶íŠ¹ë³„ìì¹˜ë„": "ì „ë¼ë¶ë„",
        }

        # í†µí•©ì´ í•„ìš”í•œ ì‹œ ëª©ë¡ ì •ì˜ (ì‚¬ìš©ì ìš”ì²­ ê¸°ì¤€)
        self.consolidation_rules = {
            # ê²½ê¸°ë„
            "ê²½ê¸°ë„ ê³ ì–‘ì‹œ": [
                "ê²½ê¸°ë„ ê³ ì–‘ì‹œ ë•ì–‘êµ¬",
                "ê²½ê¸°ë„ ê³ ì–‘ì‹œ ì¼ì‚°ë™êµ¬",
                "ê²½ê¸°ë„ ê³ ì–‘ì‹œ ì¼ì‚°ì„œêµ¬",
            ],
            "ê²½ê¸°ë„ ì„±ë‚¨ì‹œ": [
                "ê²½ê¸°ë„ ì„±ë‚¨ì‹œ ìˆ˜ì •êµ¬",
                "ê²½ê¸°ë„ ì„±ë‚¨ì‹œ ì¤‘ì›êµ¬",
                "ê²½ê¸°ë„ ì„±ë‚¨ì‹œ ë¶„ë‹¹êµ¬",
            ],
            "ê²½ê¸°ë„ ìˆ˜ì›ì‹œ": [
                "ê²½ê¸°ë„ ìˆ˜ì›ì‹œ ì˜í†µêµ¬",
                "ê²½ê¸°ë„ ìˆ˜ì›ì‹œ ì¥ì•ˆêµ¬",
                "ê²½ê¸°ë„ ìˆ˜ì›ì‹œ íŒ”ë‹¬êµ¬",
                "ê²½ê¸°ë„ ìˆ˜ì›ì‹œ ê¶Œì„ êµ¬",
            ],
            "ê²½ê¸°ë„ ì•ˆì‚°ì‹œ": ["ê²½ê¸°ë„ ì•ˆì‚°ì‹œ ë‹¨ì›êµ¬", "ê²½ê¸°ë„ ì•ˆì‚°ì‹œ ìƒë¡êµ¬"],
            "ê²½ê¸°ë„ ì•ˆì–‘ì‹œ": ["ê²½ê¸°ë„ ì•ˆì–‘ì‹œ ë§Œì•ˆêµ¬", "ê²½ê¸°ë„ ì•ˆì–‘ì‹œ ë™ì•ˆêµ¬"],
            "ê²½ê¸°ë„ ìš©ì¸ì‹œ": [
                "ê²½ê¸°ë„ ìš©ì¸ì‹œ ê¸°í¥êµ¬",
                "ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬",
                "ê²½ê¸°ë„ ìš©ì¸ì‹œ ì²˜ì¸êµ¬",
            ],
            # ê²½ìƒë‚¨ë„
            "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ": [
                "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ ì˜ì°½êµ¬",
                "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ ì„±ì‚°êµ¬",
                "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ ë§ˆì‚°í•©í¬êµ¬",
                "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ ë§ˆì‚°íšŒì›êµ¬",
                "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ ì§„í•´êµ¬",
            ],
            # ê²½ìƒë¶ë„
            "ê²½ìƒë¶ë„ í¬í•­ì‹œ": ["ê²½ìƒë¶ë„ í¬í•­ì‹œ ë‚¨êµ¬", "ê²½ìƒë¶ë„ í¬í•­ì‹œ ë¶êµ¬"],
            # ì „ë¼ë¶ë„
            "ì „ë¼ë¶ë„ ì „ì£¼ì‹œ": ["ì „ë¼ë¶ë„ ì „ì£¼ì‹œ ì™„ì‚°êµ¬", "ì „ë¼ë¶ë„ ì „ì£¼ì‹œ ë•ì§„êµ¬"],
            # ì œì£¼íŠ¹ë³„ìì¹˜ë„
            "ì œì£¼íŠ¹ë³„ìì¹˜ë„": ["ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ", "ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì„œê·€í¬ì‹œ"],
            # ì¶©ì²­ë‚¨ë„
            "ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œ": ["ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œ ë™ë‚¨êµ¬", "ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œ ì„œë¶êµ¬"],
            # ì¶©ì²­ë¶ë„
            "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œ": [
                "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œ ìƒë‹¹êµ¬",
                "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œ ì„œì›êµ¬",
                "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œ í¥ë•êµ¬",
                "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œ ì²­ì›êµ¬",
            ],
        }

        # ì—­ë°©í–¥ ë§¤í•‘ ìƒì„± (êµ¬ ì´ë¦„ â†’ í†µí•©ëœ ì‹œ ì´ë¦„)
        self.district_to_city = {}
        for city, districts in self.consolidation_rules.items():
            for district in districts:
                self.district_to_city[district] = city

        print(
            f"ğŸ›ï¸ í†µí•© ê·œì¹™ ë¡œë“œ ì™„ë£Œ: {len(self.consolidation_rules)}ê°œ ì‹œ, {sum(len(v) for v in self.consolidation_rules.values())}ê°œ êµ¬"
        )
        print(f"ğŸ“ ì‹œë„ëª… í‘œì¤€í™” ê·œì¹™: {len(self.province_standardization)}ê°œ")

    def standardize_region_name(self, region_name):
        """ì§€ì—­ëª…ì„ í‘œì¤€í™”í•˜ì—¬ í†µí•© ëŒ€ìƒì¸ì§€ í™•ì¸í•˜ê³  ë³€í™˜"""
        if pd.isna(region_name) or region_name == "":
            return region_name

        region_name = str(region_name).strip()

        # 1ë‹¨ê³„: ì‹œë„ëª… í‘œì¤€í™” (íŠ¹ë³„ìì¹˜ë„ â†’ ì¼ë°˜ ëª…ì¹­)
        for old_province, new_province in self.province_standardization.items():
            if region_name.startswith(old_province):
                region_name = region_name.replace(old_province, new_province, 1)
                break

        # 2ë‹¨ê³„: êµ¬ í†µí•© (êµ¬ë³„ ì§€ì—­ â†’ ì‹œ ë‹¨ìœ„ í†µí•©)
        if region_name in self.district_to_city:
            return self.district_to_city[region_name]

        return region_name

    def consolidate_dataframe(self, df, region_column="ì „ì¶œí–‰ì •ê¸°ê´€ëª…_í˜„ì¬"):
        """ë°ì´í„°í”„ë ˆì„ì˜ ì§€ì—­ëª…ì„ í†µí•© ì²˜ë¦¬"""
        if region_column not in df.columns:
            print(f"âš ï¸ ì§€ì—­ëª… ì»¬ëŸ¼ '{region_column}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
            return df

        print(f"ğŸ“ ì§€ì—­ëª… í†µí•© ì²˜ë¦¬ ì¤‘... (ì»¬ëŸ¼: {region_column})")

        # ì›ë³¸ ì§€ì—­ ìˆ˜
        original_regions = df[region_column].nunique()

        # ì§€ì—­ëª… í‘œì¤€í™” ì ìš©
        df["í†µí•©ì§€ì—­ëª…"] = df[region_column].apply(self.standardize_region_name)

        # ë°ì´í„° ì§‘ê³„ (ìˆ«ìí˜• ì»¬ëŸ¼ë“¤ì„ í•©ê³„)
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        non_numeric_columns = [
            col
            for col in df.columns
            if col not in numeric_columns and col != region_column
        ]

        # ê·¸ë£¹í™” ë° ì§‘ê³„
        if numeric_columns:
            # ìˆ«ìí˜• ì»¬ëŸ¼ì€ í•©ê³„
            agg_dict = {col: "sum" for col in numeric_columns}

            # ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ì¤‘ ì²« ë²ˆì§¸ ê°’ ìœ ì§€
            for col in non_numeric_columns:
                if col != "í†µí•©ì§€ì—­ëª…":
                    agg_dict[col] = "first"

            consolidated_df = df.groupby("í†µí•©ì§€ì—­ëª…").agg(agg_dict).reset_index()
            consolidated_df.rename(columns={"í†µí•©ì§€ì—­ëª…": region_column}, inplace=True)
        else:
            consolidated_df = df.copy()
            consolidated_df[region_column] = consolidated_df["í†µí•©ì§€ì—­ëª…"]
            consolidated_df.drop("í†µí•©ì§€ì—­ëª…", axis=1, inplace=True)

        # í†µí•© ê²°ê³¼
        consolidated_regions = consolidated_df[region_column].nunique()

        print(
            f"  âœ… ì§€ì—­ ìˆ˜: {original_regions} â†’ {consolidated_regions} ({original_regions - consolidated_regions}ê°œ í†µí•©)"
        )

        return consolidated_df

    def consolidate_csv_columns(self, csv_file_path):
        """CSV íŒŒì¼ì˜ ì»¬ëŸ¼ì„ í†µí•© (ê°™ì€ ì‹œë¡œ í†µí•©ë˜ëŠ” ì»¬ëŸ¼ë“¤ì˜ ê°’ì„ í•©ì¹¨)"""
        try:
            # CSV íŒŒì¼ ì½ê¸°
            df = pd.read_csv(csv_file_path, encoding="utf-8-sig")
            original_columns = df.columns.tolist()

            print(f"    ğŸ“Š ì›ë³¸ ì»¬ëŸ¼ ìˆ˜: {len(original_columns)}")

            # í—¤ë” í‘œì¤€í™” ì ìš©
            standardized_headers = {}
            for col in original_columns:
                standardized_col = col.strip()

                # 1ë‹¨ê³„: ì‹œë„ëª… í‘œì¤€í™” (íŠ¹ë³„ìì¹˜ë„ â†’ ì¼ë°˜ ëª…ì¹­)
                for old_province, new_province in self.province_standardization.items():
                    if standardized_col.startswith(old_province):
                        standardized_col = standardized_col.replace(
                            old_province, new_province, 1
                        )
                        break

                # 2ë‹¨ê³„: êµ¬ í†µí•© (êµ¬ë³„ ì§€ì—­ â†’ ì‹œ ë‹¨ìœ„ í†µí•©)
                if standardized_col in self.district_to_city:
                    standardized_col = self.district_to_city[standardized_col]

                standardized_headers[col] = standardized_col

            # ê°™ì€ ì´ë¦„ìœ¼ë¡œ í†µí•©ë˜ëŠ” ì»¬ëŸ¼ë“¤ ì°¾ê¸°
            consolidated_groups = {}
            for original_col, standardized_col in standardized_headers.items():
                if standardized_col not in consolidated_groups:
                    consolidated_groups[standardized_col] = []
                consolidated_groups[standardized_col].append(original_col)

            # ìƒˆë¡œìš´ DataFrame ìƒì„±
            new_df = pd.DataFrame()

            for standardized_col, original_cols in consolidated_groups.items():
                if len(original_cols) == 1:
                    # í†µí•©ì´ í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ì€ ê·¸ëŒ€ë¡œ ë³µì‚¬
                    new_df[standardized_col] = df[original_cols[0]]
                else:
                    # ì—¬ëŸ¬ ì»¬ëŸ¼ì„ í•©ì³ì•¼ í•˜ëŠ” ê²½ìš°
                    print(
                        f"    ğŸ”— ì»¬ëŸ¼ í†µí•©: {len(original_cols)}ê°œ â†’ {standardized_col}"
                    )
                    print(f"      â””â”€ {', '.join(original_cols)}")

                    # ìˆ«ìí˜• ì»¬ëŸ¼ì¸ì§€ í™•ì¸
                    numeric_data = []
                    for col in original_cols:
                        try:
                            # ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                            numeric_col = pd.to_numeric(df[col], errors="coerce")
                            numeric_data.append(numeric_col)
                        except:
                            # ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬
                            numeric_data.append(pd.Series([0] * len(df)))

                    # ì»¬ëŸ¼ë“¤ì˜ ê°’ì„ í•©ê³„
                    if numeric_data:
                        new_df[standardized_col] = pd.concat(numeric_data, axis=1).sum(
                            axis=1
                        )
                    else:
                        # ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° ì²« ë²ˆì§¸ ì»¬ëŸ¼ ê°’ ì‚¬ìš©
                        new_df[standardized_col] = df[original_cols[0]]

            # íŒŒì¼ ì €ì¥
            new_df.to_csv(csv_file_path, index=False, encoding="utf-8-sig")

            print(
                f"    âœ… ì»¬ëŸ¼ í†µí•© ì™„ë£Œ: {len(original_columns)} â†’ {len(new_df.columns)} ì»¬ëŸ¼"
            )

        except Exception as e:
            print(f"    âŒ ì»¬ëŸ¼ í†µí•© ì˜¤ë¥˜: {e}")

    def standardize_csv_headers(self, csv_file_path):
        """CSV íŒŒì¼ì˜ í—¤ë”ë¥¼ í‘œì¤€í™” (íŒŒì¼ ì§ì ‘ ìˆ˜ì •) - êµ¬ë²„ì „, consolidate_csv_columns ì‚¬ìš© ê¶Œì¥"""
        try:
            # CSV íŒŒì¼ ì½ê¸°
            with open(csv_file_path, "r", encoding="utf-8-sig") as f:
                content = f.read()

            # ì²« ë²ˆì§¸ ì¤„(í—¤ë”) ë¶„ë¦¬
            lines = content.split("\n")
            if lines:
                header_line = lines[0]
                header_columns = header_line.split(",")

                # ê° í—¤ë” ì»¬ëŸ¼ì— ëŒ€í•´ í‘œì¤€í™” ì ìš©
                standardized_columns = []
                for col in header_columns:
                    col = col.strip()

                    # 1ë‹¨ê³„: ì‹œë„ëª… í‘œì¤€í™” (íŠ¹ë³„ìì¹˜ë„ â†’ ì¼ë°˜ ëª…ì¹­)
                    for (
                        old_province,
                        new_province,
                    ) in self.province_standardization.items():
                        if col.startswith(old_province):
                            col = col.replace(old_province, new_province, 1)
                            break

                    # 2ë‹¨ê³„: êµ¬ í†µí•© (êµ¬ë³„ ì§€ì—­ â†’ ì‹œ ë‹¨ìœ„ í†µí•©)
                    if col in self.district_to_city:
                        col = self.district_to_city[col]

                    standardized_columns.append(col)

                # ì¤‘ë³µ ì»¬ëŸ¼ ì²˜ë¦¬ (ê°™ì€ ì‹œ ë‹¨ìœ„ë¡œ í†µí•©ëœ ê²½ìš°)
                unique_columns = []
                seen_columns = set()
                for col in standardized_columns:
                    if col not in seen_columns:
                        unique_columns.append(col)
                        seen_columns.add(col)
                    else:
                        # ì¤‘ë³µëœ ì»¬ëŸ¼ì€ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ì„œ êµ¬ë¶„
                        counter = 2
                        new_col = f"{col}_{counter}"
                        while new_col in seen_columns:
                            counter += 1
                            new_col = f"{col}_{counter}"
                        unique_columns.append(new_col)
                        seen_columns.add(new_col)

                # ìˆ˜ì •ëœ í—¤ë”ë¡œ êµì²´
                lines[0] = ",".join(unique_columns)

                # íŒŒì¼ ë‹¤ì‹œ ì €ì¥
                with open(csv_file_path, "w", encoding="utf-8-sig") as f:
                    f.write("\n".join(lines))

                print(
                    f"    ğŸ“ í—¤ë” í‘œì¤€í™” ì™„ë£Œ: {len(header_columns)} â†’ {len(unique_columns)} ì»¬ëŸ¼"
                )

        except Exception as e:
            print(f"  âš ï¸ í—¤ë” í‘œì¤€í™” ì˜¤ë¥˜: {e}")

    def process_migration_files(self, source_dir, target_dir=None):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ë“¤ì„ ì¼ê´„ ì²˜ë¦¬í•˜ì—¬ ì§€ì—­ëª… í†µí•©"""
        source_path = Path(source_dir)

        if target_dir is None:
            target_dir = source_path.parent / f"{source_path.name}_consolidated"

        target_path = Path(target_dir)
        target_path.mkdir(exist_ok=True)

        print(f"ğŸ“‚ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬: {source_path}")
        print(f"ğŸ“‚ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {target_path}")

        # CSV íŒŒì¼ ì°¾ê¸°
        csv_files = list(source_path.glob("*.csv"))
        if not csv_files:
            print("âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        print(f"ğŸ“„ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(csv_files)}")

        processed_count = 0
        for csv_file in csv_files:
            try:
                print(f"\nğŸ”„ ì²˜ë¦¬ ì¤‘: {csv_file.name}")

                # íŒŒì¼ ë¡œë“œ
                df = pd.read_csv(csv_file, encoding="utf-8-sig")
                print(f"  ğŸ“Š ì›ë³¸ ë°ì´í„°: {df.shape}")

                # ì§€ì—­ëª… ì»¬ëŸ¼ ìë™ ê°ì§€
                possible_region_cols = [
                    "ì „ì¶œí–‰ì •ê¸°ê´€ëª…_í˜„ì¬",
                    "ì „ì¶œí–‰ì •ê¸°ê´€ëª…",
                    "ì§€ì—­ëª…",
                    "ì‹œë„",
                    "ì‹œêµ°êµ¬",
                    "í–‰ì •êµ¬ì—­",
                    "ì§€ì—­",
                ]

                region_col = None
                for col in possible_region_cols:
                    if col in df.columns:
                        region_col = col
                        break

                if region_col is None:
                    print(
                        f"  âš ï¸ ì§€ì—­ëª… ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©: {df.columns[0]}"
                    )
                    region_col = df.columns[0]

                # ì§€ì—­ëª… í†µí•© ì²˜ë¦¬
                consolidated_df = self.consolidate_dataframe(df, region_col)

                # íŒŒì¼ ì €ì¥
                output_file = target_path / csv_file.name
                consolidated_df.to_csv(output_file, index=False, encoding="utf-8-sig")

                # ì»¬ëŸ¼ í†µí•© í›„ì²˜ë¦¬ (ê°™ì€ ì‹œë¡œ í†µí•©ë˜ëŠ” ì»¬ëŸ¼ë“¤ì˜ ê°’ì„ í•©ì¹¨)
                self.consolidate_csv_columns(output_file)

                print(f"  âœ… ì €ì¥ ì™„ë£Œ: {output_file.name}")
                processed_count += 1

            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

        print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ: {processed_count}/{len(csv_files)} íŒŒì¼")
        return True

    def get_consolidation_summary(self):
        """í†µí•© ê·œì¹™ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        summary = {
            "ì´_í†µí•©_ì‹œ_ìˆ˜": len(self.consolidation_rules),
            "ì´_í†µí•©_êµ¬_ìˆ˜": sum(
                len(districts) for districts in self.consolidation_rules.values()
            ),
            "ì‹œë„ëª…_í‘œì¤€í™”_ê·œì¹™ìˆ˜": len(self.province_standardization),
            "í†µí•©_ê·œì¹™": self.consolidation_rules,
            "ì‹œë„ëª…_í‘œì¤€í™”": self.province_standardization,
        }
        return summary


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì§€ì—­ëª… í†µí•© ì²˜ë¦¬ ì‹œì‘")
    print("=" * 50)

    # í†µí•©ê¸° ìƒì„±
    consolidator = RegionConsolidator()

    # í†µí•© ê·œì¹™ ìš”ì•½ ì¶œë ¥
    summary = consolidator.get_consolidation_summary()
    print(
        f"ğŸ“‹ í†µí•© ëŒ€ìƒ: {summary['ì´_í†µí•©_ì‹œ_ìˆ˜']}ê°œ ì‹œ, {summary['ì´_í†µí•©_êµ¬_ìˆ˜']}ê°œ êµ¬"
    )
    print(f"ğŸ“ ì‹œë„ëª… í‘œì¤€í™”: {summary['ì‹œë„ëª…_í‘œì¤€í™”_ê·œì¹™ìˆ˜']}ê°œ ê·œì¹™")

    # ì‹œë„ëª… í‘œì¤€í™” ê·œì¹™ ì¶œë ¥
    for old_name, new_name in summary["ì‹œë„ëª…_í‘œì¤€í™”"].items():
        print(f"   â€¢ {old_name} â†’ {new_name}")

    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
    base_path = Path(__file__).parent

    # ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰ ë°ì´í„° ì²˜ë¦¬
    youth_migration_dir = base_path / "ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰"

    if youth_migration_dir.exists():
        print(f"\nğŸ“ ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰ ë°ì´í„° ì²˜ë¦¬...")
        consolidator.process_migration_files(youth_migration_dir)
    else:
        print(f"âš ï¸ ì²­ë…„ ì¸êµ¬ ì´ë™ëŸ‰ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {youth_migration_dir}")

    print("\nâœ¨ ì§€ì—­ëª… í†µí•© ì²˜ë¦¬ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
